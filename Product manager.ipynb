{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e71a6306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18400c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from google import genai\n",
    "from tavily import TavilyClient\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Callable, Any, Dict, Optional\n",
    "from memory_system import (\n",
    "    MemoryStore, MemoryRetriever, FeedbackHandler, \n",
    "    ContextBuilder, AgentMemoryIntegration\n",
    ")\n",
    "from reflection_system import ReflectionWorkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f59d42a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration\n",
    "MODEL_PROVIDER = \"google\"  # Options: \"google\", \"fathom\", \"openai\", etc.\n",
    "MODEL_NAME = \"gemini-2.5-pro\"  # Default model name\n",
    "\n",
    "# Model-specific configurations\n",
    "MODEL_CONFIGS = {\n",
    "    \"google\": {\n",
    "        \"api_key_env\": \"GOOGLE_API_KEY\",\n",
    "        \"default_model\": \"gemini-2.5-pro\"\n",
    "    },\n",
    "    \"fathom\": {\n",
    "        \"api_key_env\": \"FATHOM_API_KEY\",\n",
    "        \"default_model\": \"fathom-1\",  # Adjust to your model name\n",
    "        \"base_url\": \"https://api.fathom.ai/v1\"  # Adjust to your API endpoint\n",
    "    },\n",
    "    \"openai\": {\n",
    "        \"api_key_env\": \"OPENAI_API_KEY\",\n",
    "        \"default_model\": \"gpt-4\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9b27e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifiedLLMClient:\n",
    "    \"\"\"Wrapper to support multiple LLM providers with a unified interface.\"\"\"\n",
    "    \n",
    "    def __init__(self, provider: str, model: str = None):\n",
    "        self.provider = provider.lower()\n",
    "        self.config = MODEL_CONFIGS.get(self.provider)\n",
    "        \n",
    "        if not self.config:\n",
    "            raise ValueError(f\"Unsupported provider: {provider}\")\n",
    "        \n",
    "        self.model = model or self.config[\"default_model\"]\n",
    "        self.api_key = os.environ.get(self.config[\"api_key_env\"])\n",
    "        \n",
    "        if not self.api_key:\n",
    "            raise ValueError(f\"API key not found for {provider}. Set {self.config['api_key_env']} in .env\")\n",
    "        \n",
    "        self._initialize_client()\n",
    "    \n",
    "    def _initialize_client(self):\n",
    "        \"\"\"Initialize the appropriate client based on provider.\"\"\"\n",
    "        if self.provider == \"google\":\n",
    "            from google import genai\n",
    "            self.client = genai.Client(api_key=self.api_key)\n",
    "            \n",
    "        elif self.provider == \"fathom\":\n",
    "            # If Fathom uses OpenAI-compatible API\n",
    "            from openai import OpenAI\n",
    "            self.client = OpenAI(\n",
    "                api_key=self.api_key,\n",
    "                base_url=self.config.get(\"base_url\")\n",
    "            )\n",
    "            \n",
    "        elif self.provider == \"openai\":\n",
    "            from openai import OpenAI\n",
    "            self.client = OpenAI(api_key=self.api_key)\n",
    "    \n",
    "    def generate_content(self, contents: str, config: dict = None):\n",
    "        \"\"\"Unified method to generate content across providers.\"\"\"\n",
    "        if self.provider == \"google\":\n",
    "            return self.client.models.generate_content(\n",
    "                model=self.model,\n",
    "                contents=contents,\n",
    "                config=config\n",
    "            )\n",
    "        \n",
    "        elif self.provider in [\"fathom\", \"openai\"]:\n",
    "            # OpenAI-style API\n",
    "            system_instruction = config.get('system_instruction', '') if config else ''\n",
    "            \n",
    "            messages = []\n",
    "            if system_instruction:\n",
    "                messages.append({\"role\": \"system\", \"content\": system_instruction})\n",
    "            messages.append({\"role\": \"user\", \"content\": contents})\n",
    "            \n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages\n",
    "            )\n",
    "            \n",
    "            # Wrap response to match Google's format\n",
    "            class ResponseWrapper:\n",
    "                def __init__(self, text):\n",
    "                    self.text = text\n",
    "            \n",
    "            return ResponseWrapper(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fc620c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tavily client\n",
    "#client = genai.Client(api_key=os.environ.get('GOOGLE_API_KEY'))\n",
    "#model=\"gemini-2.5-pro\"\n",
    "tavily_client = TavilyClient(api_key=os.environ.get('TAVILY_API_KEY')) # Initialize Tavily client\n",
    "\n",
    "# Initialize unified client\n",
    "unified_client = UnifiedLLMClient(\n",
    "    provider=MODEL_PROVIDER,\n",
    "    model=MODEL_NAME\n",
    ")\n",
    "\n",
    "# Initialize memory system\n",
    "memory_store = MemoryStore(\"pm_agent_memory.db\")\n",
    "retriever = MemoryRetriever(memory_store)\n",
    "feedback_handler = FeedbackHandler(memory_store)\n",
    "context_builder = ContextBuilder(retriever)\n",
    "memory_integration = AgentMemoryIntegration(\n",
    "    memory_store, retriever, feedback_handler, context_builder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a37c11cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agents\n",
    "\n",
    "class LeadArchitectAgent:\n",
    "    \"\"\"Lead Architect/Engineer Agent that designs system architecture and development plans.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str, client, memory_integration: AgentMemoryIntegration, num_reflections: int = 0):\n",
    "        self.model = model\n",
    "        self.client = client\n",
    "        self.memory_integration = memory_integration\n",
    "        self.conversation_history = []\n",
    "        self.num_reflections = num_reflections\n",
    "        self.reflection_workflow = ReflectionWorkflow(client, model, num_reflections)\n",
    "        self.system_instruction = \"\"\"You are a Lead Software Architect and Engineering Manager with deep expertise in:\n",
    "        - System architecture and design patterns (microservices, event-driven, monolithic, etc.)\n",
    "        - Backend and frontend technologies (Python, JavaScript/TypeScript, React, Node.js, etc.)\n",
    "        - Database design (SQL, NoSQL, data modeling, scaling strategies)\n",
    "        - Cloud infrastructure (AWS, GCP, Azure) and DevOps practices\n",
    "        - API design (REST, GraphQL, gRPC)\n",
    "        - Security best practices and compliance\n",
    "        - Performance optimization and scalability\n",
    "        - Code quality, testing strategies, and CI/CD\n",
    "        - Effort estimation and sprint planning\n",
    "        - Which engineering skillsets are needed for different tasks (frontend, backend, data engineering, DevOps, etc.)\n",
    "        - Technical debt management\n",
    "        - Team coordination and technical leadership\n",
    "\n",
    "        You analyze product requirements, UX designs, and statistical constraints to:\n",
    "        1. Design robust, scalable system architectures\n",
    "        2. Recommend appropriate technology stacks\n",
    "        3. Create detailed technical specifications\n",
    "        4. Provide realistic effort estimates (in story points or hours)\n",
    "        5. Identify technical risks and dependencies\n",
    "        6. Suggest phased implementation approaches\n",
    "        7. Consider maintainability, security, and performance from the start\n",
    "        \n",
    "        You communicate technical concepts clearly to both technical and non-technical stakeholders,\n",
    "        and always balance ideal solutions with practical constraints like timeline, budget, and team skills.\n",
    "        \n",
    "        If you are provided with search results, memories, or reflections, incorporate relevant information into your response, but don't acknowledge them explicitly.\"\"\"\n",
    "    \n",
    "    def __call__(self, requirements: str, num_reflections: Optional[int] = None, verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Design architecture and development plan based on requirements.\n",
    "        \n",
    "        Args:\n",
    "            requirements: The requirements/specs (from user, PM, UX, or statistician)\n",
    "            num_reflections: Number of reflections for this specific query\n",
    "            verbose: If True, returns reflection data\n",
    "            \n",
    "        Returns:\n",
    "            (response, memory_id) tuple or (response, memory_id, reflection_data) if verbose\n",
    "        \"\"\"\n",
    "        reflections_to_use = num_reflections if num_reflections is not None else self.num_reflections\n",
    "        \n",
    "        # Get memory context\n",
    "        memory_context = self.memory_integration.pre_run_hook(requirements, \"architecture_design\")\n",
    "\n",
    "        # Check if web search needed for technologies or patterns\n",
    "        decision_prompt = f\"\"\"Analyze this architecture/engineering request and determine if you need to search for \n",
    "recent technologies, frameworks, design patterns, or best practices.\n",
    "\n",
    "Request: {requirements}\n",
    "\n",
    "Respond with ONLY \"YES\" or \"NO\":\"\"\"\n",
    "\n",
    "        decision_response = self.client.models.generate_content(\n",
    "            model=self.model,\n",
    "            contents=decision_prompt\n",
    "        )\n",
    "        \n",
    "        needs_search = \"YES\" in decision_response.text.strip().upper()\n",
    "        \n",
    "        search_context = \"\"\n",
    "        if needs_search:\n",
    "            print(\"üîç Searching for architecture patterns and technologies...\")\n",
    "            search_results = search_web(f\"software architecture best practices {requirements[:100]}\")\n",
    "            if isinstance(search_results, list):\n",
    "                search_context = \"\\n\\nTechnology & Architecture Research:\\n\"\n",
    "                for i, result in enumerate(search_results, 1):\n",
    "                    search_context += f\"\\n{i}. {result.get('title', '')}\\n{result.get('content', '')}\\n\"\n",
    "        \n",
    "        # Build conversation context\n",
    "        conversation_context = \"\"\n",
    "        if self.conversation_history:\n",
    "            conversation_context = \"\\n\\nPrevious architecture decisions:\\n\"\n",
    "            for entry in self.conversation_history[-3:]:\n",
    "                conversation_context += f\"Requirements: {entry['requirements'][:200]}...\\nArchitecture: {entry['response'][:300]}...\\n\\n\"\n",
    "\n",
    "        def generate_response(query: str) -> str:\n",
    "            full_query = (\n",
    "                memory_context +\n",
    "                conversation_context + \n",
    "                f\"\\nDesign system architecture and development plan for:\\n{query}\\n\\n\"\n",
    "                \"Structure your response with:\\n\"\n",
    "                \"1. **System Architecture Overview**: High-level architecture diagram description and key components\\n\"\n",
    "                \"2. **Technology Stack**: Recommended technologies with justifications\\n\"\n",
    "                \"3. **Data Architecture**: Database design, data flows, and storage strategies\\n\"\n",
    "                \"4. **API Design**: Endpoints, data contracts, and integration points\\n\"\n",
    "                \"5. **Security & Compliance**: Authentication, authorization, data protection\\n\"\n",
    "                \"6. **Development Plan**: Phased implementation approach with milestones\\n\"\n",
    "                \"7. **Effort Estimates**: Story points or time estimates per component/phase\\n\"\n",
    "                \"8. **Technical Risks**: Potential challenges and mitigation strategies\" +\n",
    "                search_context\n",
    "            )\n",
    "            \n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.model,\n",
    "                contents=full_query,\n",
    "                config={'system_instruction': self.system_instruction}\n",
    "            )\n",
    "            return response.text\n",
    "        \n",
    "        if reflections_to_use > 0:\n",
    "            print(f\"ü§î Reflecting {reflections_to_use} time(s)...\")\n",
    "            self.reflection_workflow.num_reflections = reflections_to_use\n",
    "            result = self.reflection_workflow.execute(\n",
    "                initial_query=requirements,\n",
    "                generate_response_fn=generate_response,\n",
    "                system_instruction=self.system_instruction\n",
    "            )\n",
    "            final_response = result['final_response']\n",
    "            reflection_data = result\n",
    "        else:\n",
    "            final_response = generate_response(requirements)\n",
    "            reflection_data = None\n",
    "\n",
    "        self.conversation_history.append({\n",
    "            'requirements': requirements,\n",
    "            'response': final_response\n",
    "        })\n",
    "        \n",
    "        memory_id = self.memory_integration.post_run_hook(\n",
    "            requirements,\n",
    "            final_response,\n",
    "            memory_type=\"architecture_design\",\n",
    "            metadata={\n",
    "                'search_used': needs_search,\n",
    "                'num_reflections': reflections_to_use\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if verbose and reflection_data:\n",
    "            return final_response, memory_id, reflection_data\n",
    "        \n",
    "        return final_response, memory_id\n",
    "    \n",
    "    def set_reflections(self, num_reflections: int):\n",
    "        self.num_reflections = num_reflections\n",
    "        self.reflection_workflow.num_reflections = num_reflections\n",
    "        print(f\"Default reflection count updated to: {num_reflections}\")\n",
    "    \n",
    "    def apply_feedback(self, memory_id: int, feedback_type: str, feedback_content: str = \"\"):\n",
    "        self.memory_integration.apply_feedback(memory_id, feedback_type, feedback_content)\n",
    "        print(f\"Feedback '{feedback_type}' applied to memory {memory_id}\")\n",
    "        \n",
    "    def clear_history(self):\n",
    "        self.conversation_history = []\n",
    "        self.reflection_workflow.clear_history()\n",
    "        print(\"Architecture history cleared.\")\n",
    "\n",
    "class StatisticianAgent:\n",
    "    \"\"\"Statistician Agent that provides statistical validation, methodology suggestions, and risk analysis.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str, client, memory_integration: AgentMemoryIntegration, num_reflections: int = 0):\n",
    "        self.model = model\n",
    "        self.client = client\n",
    "        self.memory_integration = memory_integration\n",
    "        self.conversation_history = []\n",
    "        self.num_reflections = num_reflections\n",
    "        self.reflection_workflow = ReflectionWorkflow(client, model, num_reflections)\n",
    "        self.system_instruction = \"\"\"You are an expert Statistician and Data Scientist with deep expertise in:\n",
    "        - Experimental design and A/B testing methodologies\n",
    "        - Causal inference techniques (propensity score matching, instrumental variables, difference-in-differences, RCTs)\n",
    "        - Statistical hypothesis testing and power analysis\n",
    "        - Observational study design and confounding control\n",
    "        - Sample size calculations and statistical power\n",
    "        - Bayesian and frequentist inference\n",
    "        - Time series analysis and longitudinal data methods\n",
    "        - Machine learning validation and model evaluation\n",
    "        - Data quality assessment and bias detection\n",
    "        - Privacy-preserving statistical methods\n",
    "        - Communicating statistical concepts to non-technical stakeholders\n",
    "\n",
    "        You analyze product plans, research designs, and data strategies to:\n",
    "        1. Validate statistical assumptions and methodological soundness\n",
    "        2. Suggest appropriate statistical techniques and experimental designs\n",
    "        3. Flag potential risks, biases, and confounding factors\n",
    "        4. Provide specific, actionable recommendations with clear rationale\n",
    "        5. Assess feasibility of causal claims and required data infrastructure\n",
    "        \n",
    "        You communicate complex statistical concepts clearly, always considering practical constraints\n",
    "        like sample size, data collection feasibility, and computational resources.\n",
    "        If you are provided with search results, memories, or reflections, incorporate relevant information into your response, but don't acknowledge them explicitly.\"\"\"\n",
    "    \n",
    "    def __call__(self, analysis_request: str, num_reflections: Optional[int] = None, verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Analyze plans/designs from a statistical perspective.\n",
    "        \n",
    "        Args:\n",
    "            analysis_request: The plan, design, or question to analyze (from user, PM, or UX researcher)\n",
    "            num_reflections: Number of reflections for this specific query\n",
    "            verbose: If True, returns reflection data\n",
    "            \n",
    "        Returns:\n",
    "            (response, memory_id) tuple or (response, memory_id, reflection_data) if verbose\n",
    "        \"\"\"\n",
    "        reflections_to_use = num_reflections if num_reflections is not None else self.num_reflections\n",
    "        \n",
    "        # Get memory context\n",
    "        memory_context = self.memory_integration.pre_run_hook(analysis_request, \"statistical_analysis\")\n",
    "\n",
    "        # Check if web search needed for recent statistical methods or research\n",
    "        decision_prompt = f\"\"\"Analyze this statistical analysis request and determine if you need to search for \n",
    "recent statistical methodologies, causal inference techniques, or research papers.\n",
    "\n",
    "Request: {analysis_request}\n",
    "\n",
    "Respond with ONLY \"YES\" or \"NO\":\"\"\"\n",
    "\n",
    "        decision_response = self.client.models.generate_content(\n",
    "            model=self.model,\n",
    "            contents=decision_prompt\n",
    "        )\n",
    "        \n",
    "        needs_search = \"YES\" in decision_response.text.strip().upper()\n",
    "        \n",
    "        search_context = \"\"\n",
    "        if needs_search:\n",
    "            print(\"üîç Searching for statistical methods and research...\")\n",
    "            search_results = search_web(f\"statistical methodology causal inference {analysis_request[:100]}\")\n",
    "            if isinstance(search_results, list):\n",
    "                search_context = \"\\n\\nRecent Statistical Methods & Research:\\n\"\n",
    "                for i, result in enumerate(search_results, 1):\n",
    "                    search_context += f\"\\n{i}. {result.get('title', '')}\\n{result.get('content', '')}\\n\"\n",
    "        \n",
    "        # Build conversation context\n",
    "        conversation_context = \"\"\n",
    "        if self.conversation_history:\n",
    "            conversation_context = \"\\n\\nPrevious statistical analyses:\\n\"\n",
    "            for entry in self.conversation_history[-3:]:\n",
    "                conversation_context += f\"Request: {entry['request']}\\nAnalysis: {entry['response'][:300]}...\\n\\n\"\n",
    "\n",
    "        def generate_response(query: str) -> str:\n",
    "            full_query = (\n",
    "                memory_context +\n",
    "                conversation_context + \n",
    "                f\"\\nProvide statistical analysis for:\\n{query}\\n\\n\"\n",
    "                \"Structure your response with:\\n\"\n",
    "                \"1. **Validation of Assumptions**: What statistical assumptions are being made?\\n\"\n",
    "                \"2. **Recommended Techniques**: Which specific statistical methods should be used?\\n\"\n",
    "                \"3. **Risk Warnings**: What are the key statistical risks and limitations?\\n\"\n",
    "                \"4. **Implementation Details**: Sample sizes, power calculations, data requirements\\n\"\n",
    "                \"5. **Causal Inference Considerations**: If applicable, how to establish causality\" +\n",
    "                search_context\n",
    "            )\n",
    "            \n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.model,\n",
    "                contents=full_query,\n",
    "                config={'system_instruction': self.system_instruction}\n",
    "            )\n",
    "            return response.text\n",
    "        \n",
    "        if reflections_to_use > 0:\n",
    "            print(f\"ü§î Reflecting {reflections_to_use} time(s)...\")\n",
    "            self.reflection_workflow.num_reflections = reflections_to_use\n",
    "            result = self.reflection_workflow.execute(\n",
    "                initial_query=analysis_request,\n",
    "                generate_response_fn=generate_response,\n",
    "                system_instruction=self.system_instruction\n",
    "            )\n",
    "            final_response = result['final_response']\n",
    "            reflection_data = result\n",
    "        else:\n",
    "            final_response = generate_response(analysis_request)\n",
    "            reflection_data = None\n",
    "\n",
    "        self.conversation_history.append({\n",
    "            'request': analysis_request,\n",
    "            'response': final_response\n",
    "        })\n",
    "        \n",
    "        memory_id = self.memory_integration.post_run_hook(\n",
    "            analysis_request,\n",
    "            final_response,\n",
    "            memory_type=\"statistical_analysis\",\n",
    "            metadata={\n",
    "                'search_used': needs_search,\n",
    "                'num_reflections': reflections_to_use\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if verbose and reflection_data:\n",
    "            return final_response, memory_id, reflection_data\n",
    "        \n",
    "        return final_response, memory_id\n",
    "    \n",
    "    def set_reflections(self, num_reflections: int):\n",
    "        self.num_reflections = num_reflections\n",
    "        self.reflection_workflow.num_reflections = num_reflections\n",
    "        print(f\"Default reflection count updated to: {num_reflections}\")\n",
    "    \n",
    "    def apply_feedback(self, memory_id: int, feedback_type: str, feedback_content: str = \"\"):\n",
    "        self.memory_integration.apply_feedback(memory_id, feedback_type, feedback_content)\n",
    "        print(f\"Feedback '{feedback_type}' applied to memory {memory_id}\")\n",
    "        \n",
    "    def clear_history(self):\n",
    "        self.conversation_history = []\n",
    "        self.reflection_workflow.clear_history()\n",
    "        print(\"Statistical analysis history cleared.\")\n",
    "\n",
    "class UXResearcherAgent:\n",
    "    \"\"\"UX Researcher Agent that conducts user research based on product briefs.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str, client, memory_integration: AgentMemoryIntegration, num_reflections: int = 0):\n",
    "        self.model = model\n",
    "        self.client = client\n",
    "        self.memory_integration = memory_integration\n",
    "        self.conversation_history = []\n",
    "        self.num_reflections = num_reflections\n",
    "        self.reflection_workflow = ReflectionWorkflow(client, model, num_reflections)\n",
    "        self.system_instruction = \"\"\"You are an experienced UX Researcher with expertise in:\n",
    "        - User interviews and surveys\n",
    "        - Usability testing and evaluation\n",
    "        - User personas and journey mapping\n",
    "        - Information architecture\n",
    "        - Behavioral analysis and user psychology\n",
    "        - A/B testing and experimentation\n",
    "        - Accessibility and inclusive design\n",
    "        - Analytics interpretation\n",
    "        - Presenting research findings and recommendations\n",
    "\n",
    "        You analyze product briefs and provide detailed UX research plans, methodologies, \n",
    "        and insights. You ask clarifying questions about target users, use cases, and \n",
    "        constraints. You base your recommendations on established UX principles and research methods.\n",
    "        If you are provided with search results, memories, or reflections, incorporate relevant information into your response, but don't acknowledge them explicitly.\"\"\"\n",
    "    \n",
    "    def __call__(self, brief: str, num_reflections: Optional[int] = None, verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Process a product brief and provide UX research recommendations.\n",
    "        \n",
    "        Args:\n",
    "            brief: The product brief (from user or PM agent)\n",
    "            num_reflections: Number of reflections for this specific query\n",
    "            verbose: If True, returns reflection data\n",
    "            \n",
    "        Returns:\n",
    "            (response, memory_id) tuple or (response, memory_id, reflection_data) if verbose\n",
    "        \"\"\"\n",
    "        reflections_to_use = num_reflections if num_reflections is not None else self.num_reflections\n",
    "        \n",
    "        # Get memory context\n",
    "        memory_context = self.memory_integration.pre_run_hook(brief, \"ux_research\")\n",
    "\n",
    "        # Check if web search needed for UX best practices\n",
    "        decision_prompt = f\"\"\"Analyze this UX research brief and determine if you need to search for current UX best practices, research methodologies, or industry standards.\n",
    "\n",
    "Brief: {brief}\n",
    "\n",
    "Respond with ONLY \"YES\" or \"NO\":\"\"\"\n",
    "\n",
    "        decision_response = self.client.models.generate_content(\n",
    "            model=self.model,\n",
    "            contents=decision_prompt\n",
    "        )\n",
    "        \n",
    "        needs_search = \"YES\" in decision_response.text.strip().upper()\n",
    "        \n",
    "        search_context = \"\"\n",
    "        if needs_search:\n",
    "            print(\"üîç Searching for UX research best practices...\")\n",
    "            search_results = search_web(f\"UX research methodology {brief[:100]}\")\n",
    "            if isinstance(search_results, list):\n",
    "                search_context = \"\\n\\nUX Research Best Practices:\\n\"\n",
    "                for i, result in enumerate(search_results, 1):\n",
    "                    search_context += f\"\\n{i}. {result.get('title', '')}\\n{result.get('content', '')}\\n\"\n",
    "        \n",
    "        # Build conversation context\n",
    "        conversation_context = \"\"\n",
    "        if self.conversation_history:\n",
    "            conversation_context = \"\\n\\nPrevious research context:\\n\"\n",
    "            for entry in self.conversation_history[-3:]:\n",
    "                conversation_context += f\"Brief: {entry['brief']}\\nResearch Plan: {entry['response']}\\n\\n\"\n",
    "\n",
    "        def generate_response(query: str) -> str:\n",
    "            full_query = (\n",
    "                memory_context +\n",
    "                conversation_context + \n",
    "                f\"\\n{query}\" +\n",
    "                search_context\n",
    "            )\n",
    "            \n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.model,\n",
    "                contents=full_query,\n",
    "                config={'system_instruction': self.system_instruction}\n",
    "            )\n",
    "            return response.text\n",
    "        \n",
    "        if reflections_to_use > 0:\n",
    "            print(f\"ü§î Reflecting {reflections_to_use} time(s)...\")\n",
    "            self.reflection_workflow.num_reflections = reflections_to_use\n",
    "            result = self.reflection_workflow.execute(\n",
    "                initial_query=brief,\n",
    "                generate_response_fn=generate_response,\n",
    "                system_instruction=self.system_instruction\n",
    "            )\n",
    "            final_response = result['final_response']\n",
    "            reflection_data = result\n",
    "        else:\n",
    "            final_response = generate_response(brief)\n",
    "            reflection_data = None\n",
    "\n",
    "        self.conversation_history.append({\n",
    "            'brief': brief,\n",
    "            'response': final_response\n",
    "        })\n",
    "        \n",
    "        memory_id = self.memory_integration.post_run_hook(\n",
    "            brief,\n",
    "            final_response,\n",
    "            memory_type=\"ux_research\",\n",
    "            metadata={\n",
    "                'search_used': needs_search,\n",
    "                'num_reflections': reflections_to_use\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if verbose and reflection_data:\n",
    "            return final_response, memory_id, reflection_data\n",
    "        \n",
    "        return final_response, memory_id\n",
    "    \n",
    "    def set_reflections(self, num_reflections: int):\n",
    "        self.num_reflections = num_reflections\n",
    "        self.reflection_workflow.num_reflections = num_reflections\n",
    "        print(f\"Default reflection count updated to: {num_reflections}\")\n",
    "    \n",
    "    def apply_feedback(self, memory_id: int, feedback_type: str, feedback_content: str = \"\"):\n",
    "        self.memory_integration.apply_feedback(memory_id, feedback_type, feedback_content)\n",
    "        print(f\"Feedback '{feedback_type}' applied to memory {memory_id}\")\n",
    "        \n",
    "    def clear_history(self):\n",
    "        self.conversation_history = []\n",
    "        self.reflection_workflow.clear_history()\n",
    "        print(\"Research history cleared.\")\n",
    "\n",
    "class SampleDataGeneratorAgent:\n",
    "    \"\"\"Agent that generates sample/mock data for testing and prototyping.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str, client, memory_integration: AgentMemoryIntegration, num_reflections: int = 0):\n",
    "        self.model = model\n",
    "        self.client = client\n",
    "        self.memory_integration = memory_integration\n",
    "        self.conversation_history = []\n",
    "        self.num_reflections = num_reflections\n",
    "        self.reflection_workflow = ReflectionWorkflow(client, model, num_reflections)\n",
    "        self.system_instruction = \"\"\"You are a Sample Data Generator specialist with expertise in:\n",
    "        - Creating realistic test data and mock datasets\n",
    "        - Understanding data schemas and structures\n",
    "        - Generating diverse, representative data samples\n",
    "        - Ensuring data privacy and anonymization\n",
    "        - Creating edge cases and boundary conditions\n",
    "        - Generating data in various formats (JSON, CSV, SQL, etc.)\n",
    "        - Synthetic data generation techniques\n",
    "        - Data volume scaling considerations\n",
    "\n",
    "        You generate realistic, contextually appropriate sample data based on specifications.\n",
    "        You ensure data quality, diversity, and adherence to constraints. You can generate\n",
    "        data for user profiles, transactions, interactions, or any other entities needed\n",
    "        for testing and prototyping.\n",
    "        If you are provided with search results, memories, or reflections, incorporate relevant information into your response, but don't acknowledge them explicitly.\"\"\"\n",
    "    \n",
    "    def __call__(self, specification: str, num_reflections: Optional[int] = None, verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Generate sample data based on specification.\n",
    "        \n",
    "        Args:\n",
    "            specification: Description of data to generate (schema, format, volume, etc.)\n",
    "            num_reflections: Number of reflections for this specific query\n",
    "            verbose: If True, returns reflection data\n",
    "            \n",
    "        Returns:\n",
    "            (response, memory_id) tuple or (response, memory_id, reflection_data) if verbose\n",
    "        \"\"\"\n",
    "        reflections_to_use = num_reflections if num_reflections is not None else self.num_reflections\n",
    "        \n",
    "        memory_context = self.memory_integration.pre_run_hook(specification, \"data_generation\")\n",
    "\n",
    "        # Build conversation context\n",
    "        conversation_context = \"\"\n",
    "        if self.conversation_history:\n",
    "            conversation_context = \"\\n\\nPrevious data generation context:\\n\"\n",
    "            for entry in self.conversation_history[-3:]:\n",
    "                conversation_context += f\"Spec: {entry['spec']}\\n\\n\"\n",
    "\n",
    "        def generate_response(query: str) -> str:\n",
    "            full_query = (\n",
    "                memory_context +\n",
    "                conversation_context + \n",
    "                f\"\\nGenerate sample data based on: {query}\\n\\n\"\n",
    "                \"Provide the data in a structured format with clear labels and explanations.\"\n",
    "            )\n",
    "            \n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.model,\n",
    "                contents=full_query,\n",
    "                config={'system_instruction': self.system_instruction}\n",
    "            )\n",
    "            return response.text\n",
    "        \n",
    "        if reflections_to_use > 0:\n",
    "            print(f\"ü§î Reflecting {reflections_to_use} time(s)...\")\n",
    "            self.reflection_workflow.num_reflections = reflections_to_use\n",
    "            result = self.reflection_workflow.execute(\n",
    "                initial_query=specification,\n",
    "                generate_response_fn=generate_response,\n",
    "                system_instruction=self.system_instruction\n",
    "            )\n",
    "            final_response = result['final_response']\n",
    "            reflection_data = result\n",
    "        else:\n",
    "            final_response = generate_response(specification)\n",
    "            reflection_data = None\n",
    "\n",
    "        self.conversation_history.append({\n",
    "            'spec': specification,\n",
    "            'response': final_response\n",
    "        })\n",
    "        \n",
    "        memory_id = self.memory_integration.post_run_hook(\n",
    "            specification,\n",
    "            final_response,\n",
    "            memory_type=\"data_generation\",\n",
    "            metadata={'num_reflections': reflections_to_use}\n",
    "        )\n",
    "\n",
    "        if verbose and reflection_data:\n",
    "            return final_response, memory_id, reflection_data\n",
    "        \n",
    "        return final_response, memory_id\n",
    "    \n",
    "    def set_reflections(self, num_reflections: int):\n",
    "        self.num_reflections = num_reflections\n",
    "        self.reflection_workflow.num_reflections = num_reflections\n",
    "        print(f\"Default reflection count updated to: {num_reflections}\")\n",
    "    \n",
    "    def apply_feedback(self, memory_id: int, feedback_type: str, feedback_content: str = \"\"):\n",
    "        self.memory_integration.apply_feedback(memory_id, feedback_type, feedback_content)\n",
    "        print(f\"Feedback '{feedback_type}' applied to memory {memory_id}\")\n",
    "        \n",
    "    def clear_history(self):\n",
    "        self.conversation_history = []\n",
    "        self.reflection_workflow.clear_history()\n",
    "        print(\"Data generation history cleared.\")\n",
    "\n",
    "class ProductManagerAgent:\n",
    "    \"\"\"Product Manager Agent with conversation memory and long-term learning.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str, client, memory_integration: AgentMemoryIntegration, num_reflections: int = 0):\n",
    "        self.model = model\n",
    "        self.client = client\n",
    "        self.memory_integration = memory_integration\n",
    "        self.conversation_history = []\n",
    "        self.num_reflections = num_reflections\n",
    "        self.reflection_workflow = ReflectionWorkflow(client, model, num_reflections)\n",
    "        self.system_instruction = \"\"\"You are an experienced Product Manager with expertise in:\n",
    "        - Product strategy and roadmap planning\n",
    "        - Market research and competitive analysis\n",
    "        - User research and requirements gathering\n",
    "        - Feature prioritization and backlog management\n",
    "        - Stakeholder communication\n",
    "        - Metrics and KPI definition\n",
    "        - Go-to-market strategies\n",
    "        - Agile methodologies\n",
    "        - Providing feedback to your product specialist, engineering, design, data science, testing, and marketing teams\n",
    "\n",
    "        You provide practical, actionable advice and ask clarifying questions when needed.\n",
    "        When provided with search results or past memories, incorporate relevant information into your response and cite sources.\n",
    "        If you are provided with search results, memories, or reflections, incorporate relevant information into your response, but don't acknowledge them explicitly.\"\"\"\n",
    "    \n",
    "    def __call__(self, user_query: str, num_reflections: Optional[int] = None, verbose: bool = False):\n",
    "        \"\"\"\n",
    "        Make the agent callable like a function.\n",
    "        \n",
    "        Args:\n",
    "            user_query: The user's query\n",
    "            num_reflections: Number of reflections for this specific query (overrides default)\n",
    "            verbose: If True, returns reflection data\n",
    "            \n",
    "        Returns:\n",
    "            (response, memory_id) tuple or (response, memory_id, reflection_data) if verbose\n",
    "        \"\"\"\n",
    "        # Use query-specific reflections or fall back to instance default\n",
    "        reflections_to_use = num_reflections if num_reflections is not None else self.num_reflections\n",
    "        \n",
    "        # Get memory context\n",
    "        memory_context = self.memory_integration.pre_run_hook(user_query, \"pm_interaction\")\n",
    "\n",
    "        # Decide if search is needed\n",
    "        decision_prompt = f\"\"\"Analyze this query and determine if you need web search.\n",
    "\n",
    "Query: {user_query}\n",
    "\n",
    "Respond with ONLY \"YES\" or \"NO\":\"\"\"\n",
    "\n",
    "        decision_response = self.client.models.generate_content(\n",
    "            model=self.model,\n",
    "            contents=decision_prompt\n",
    "        )\n",
    "        \n",
    "        needs_search = \"YES\" in decision_response.text.strip().upper()\n",
    "        \n",
    "        # Perform search if needed\n",
    "        search_context = \"\"\n",
    "        if needs_search:\n",
    "            print(\"üîç Searching the web...\")\n",
    "            search_results = search_web(user_query)\n",
    "            if isinstance(search_results, list):\n",
    "                search_context = \"\\n\\nWeb Search Results:\\n\"\n",
    "                for i, result in enumerate(search_results, 1):\n",
    "                    search_context += f\"\\n{i}. {result.get('title', '')}\\n{result.get('content', '')}\\n\"\n",
    "        \n",
    "        # Build conversation context\n",
    "        conversation_context = \"\"\n",
    "        if self.conversation_history:\n",
    "            conversation_context = \"\\n\\nPrevious conversation:\\n\"\n",
    "            for entry in self.conversation_history[-5:]:  # Keep last 5 exchanges\n",
    "                conversation_context += f\"User: {entry['user']}\\nAssistant: {entry['assistant']}\\n\\n\"\n",
    "\n",
    "        # Define response generation function for reflection workflow\n",
    "        def generate_response(query: str) -> str:\n",
    "            full_query = (\n",
    "                memory_context +\n",
    "                conversation_context + \n",
    "                f\"\\n{query}\" +\n",
    "                search_context\n",
    "            )\n",
    "            \n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.model,\n",
    "                contents=full_query,\n",
    "                config={'system_instruction': self.system_instruction}\n",
    "            )\n",
    "            return response.text\n",
    "        \n",
    "        # Execute with or without reflection\n",
    "        if reflections_to_use > 0:\n",
    "            print(f\"ü§î Reflecting {reflections_to_use} time(s)...\")\n",
    "            # Temporarily update reflection workflow\n",
    "            self.reflection_workflow.num_reflections = reflections_to_use\n",
    "            result = self.reflection_workflow.execute(\n",
    "                initial_query=user_query,\n",
    "                generate_response_fn=generate_response,\n",
    "                system_instruction=self.system_instruction\n",
    "            )\n",
    "            final_response = result['final_response']\n",
    "            reflection_data = result\n",
    "        else:\n",
    "            final_response = generate_response(user_query)\n",
    "            reflection_data = None\n",
    "\n",
    "        # Store in conversation history\n",
    "        self.conversation_history.append({\n",
    "            'user': user_query,\n",
    "            'assistant': final_response\n",
    "        })\n",
    "        \n",
    "        # Log to long-term memory\n",
    "        memory_id = self.memory_integration.post_run_hook(\n",
    "            user_query,\n",
    "            final_response,\n",
    "            memory_type=\"pm_interaction\",\n",
    "            metadata={\n",
    "                'search_used': needs_search, \n",
    "                'num_reflections': reflections_to_use, \n",
    "                'reflection_used': reflections_to_use > 0\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if verbose and reflection_data:\n",
    "            return final_response, memory_id, reflection_data\n",
    "        \n",
    "        return final_response, memory_id\n",
    "    \n",
    "    def set_reflections(self, num_reflections: int):\n",
    "        \"\"\"Update the default number of reflections.\"\"\"\n",
    "        self.num_reflections = num_reflections\n",
    "        self.reflection_workflow.num_reflections = num_reflections\n",
    "        print(f\"Default reflection count updated to: {num_reflections}\")\n",
    "    \n",
    "    def apply_feedback(self, memory_id: int, feedback_type: str, \n",
    "                      feedback_content: str = \"\"):\n",
    "        \"\"\"Apply feedback to a specific interaction.\"\"\"\n",
    "        self.memory_integration.apply_feedback(memory_id, feedback_type, feedback_content)\n",
    "        print(f\"Feedback '{feedback_type}' applied to memory {memory_id}\")\n",
    "        \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear conversation history.\"\"\"\n",
    "        self.conversation_history = []\n",
    "        self.reflection_workflow.clear_history()\n",
    "        print(\"Conversation history cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f93a3863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def remove_markdown(response_text):\n",
    "    \"\"\"Remove markdown formatting and print clean text.\"\"\"\n",
    "    # Remove markdown formatting\n",
    "    text = re.sub(r'\\*\\*(.+?)\\*\\*', r'\\1', response_text)  # Bold\n",
    "    text = re.sub(r'\\*(.+?)\\*', r'\\1', text)  # Italic\n",
    "    text = re.sub(r'`(.+?)`', r'\\1', text)  # Code\n",
    "    text = re.sub(r'#+\\s', '', text)  # Headers\n",
    "    return text\n",
    "def chat_with_agent(agent, agent_name=\"Agent\"):\n",
    "    \"\"\"\n",
    "    Generic interactive chat interface for any agent.\n",
    "    \n",
    "    Args:\n",
    "        agent: The agent instance (callable) to chat with\n",
    "        agent_name: Display name for the agent (default: \"Agent\")\n",
    "    \n",
    "    Type 'exit', 'quit', or 'bye' to end the conversation.\n",
    "    Type 'clear' to clear conversation history.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{agent_name} Chat\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Start chatting with the {agent_name}!\")\n",
    "    print(\"Type 'exit', 'quit', or 'bye' to end the chat.\")\n",
    "    print(\"Type 'clear' to clear conversation history.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(f\"\\n{agent_name}: Thanks for chatting! Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if user_input.lower() == 'clear':\n",
    "            if hasattr(agent, 'clear_history'):\n",
    "                agent.clear_history()\n",
    "            continue\n",
    "            \n",
    "        if not user_input:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            response = agent(user_input)\n",
    "            print(f\"\\n{agent_name}: {remove_markdown(response)}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {e}\\n\")\n",
    "            print(\"Please try again or type 'exit' to quit.\\n\")\n",
    "def search_web(query):\n",
    "    \"\"\"Search the web using Tavily.\"\"\"\n",
    "    try:\n",
    "        response = tavily_client.search(query, max_results=5)\n",
    "        return response['results']\n",
    "    except Exception as e:\n",
    "        return f\"Search error: {e}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a4a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent instances\n",
    "pm_agent = ProductManagerAgent(model=MODEL_NAME, client=unified_client, memory_integration=memory_integration)\n",
    "ux_researcher = UXResearcherAgent(model=MODEL_NAME, client=unified_client, memory_integration=memory_integration)\n",
    "data_generator = SampleDataGeneratorAgent(model=MODEL_NAME, client=unified_client, memory_integration=memory_integration)\n",
    "statistician = StatisticianAgent(model=MODEL_NAME, client=unified_client, memory_integration=memory_integration)\n",
    "lead_architect = LeadArchitectAgent(model=MODEL_NAME, client=unified_client, memory_integration=memory_integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b69a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "query = \"I want to create a project management tool for sales teams.\"\n",
    "\n",
    "num_reflections = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9dbbf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching the web...\n",
      "ü§î Reflecting 2 time(s)...\n",
      "üîç Searching for UX research best practices...\n",
      "ü§î Reflecting 2 time(s)...\n",
      "üîç Searching for statistical methods and research...\n",
      "ü§î Reflecting 2 time(s)...\n",
      "ü§î Reflecting 2 time(s)...\n",
      "ü§î Reflecting 2 time(s)...\n",
      "ü§î Reflecting 2 time(s)...\n",
      "üîç Searching for statistical methods and research...\n",
      "ü§î Reflecting 2 time(s)...\n",
      "ü§î Reflecting 2 time(s)...\n"
     ]
    }
   ],
   "source": [
    "#Workflow\n",
    "response, memory_id = pm_agent(query, num_reflections=num_reflections)\n",
    "ux_response, ux_memory_id = ux_researcher(response, num_reflections=num_reflections)\n",
    "stats_analysis, stats_memory_id = statistician(\n",
    "    f\"Please analyze this product and UX research plan from a statistical perspective:\\n\\n\"\n",
    "    f\"Product Plan: {response}\\n\\n\"\n",
    "    f\"UX Research Plan: {ux_response}\",\n",
    "    num_reflections=num_reflections\n",
    ")\n",
    "arch_design, arch_memory_id = lead_architect(\n",
    "    f\"Please design the system architecture for this product:\\n\\n\"\n",
    "    f\"Product Plan: {response}\\n\\n\"\n",
    "    f\"UX Research: {ux_response}\\n\\n\"\n",
    "    f\"Statistical Requirements: {stats_analysis}\",\n",
    "    num_reflections=num_reflections\n",
    ")\n",
    "user_stories, memory_id = pm_agent(f\"Can you create a list of user stories with acceptance criteria given these discussions?:\\n\\n\"\n",
    "                               f\"Product Plan: {response}\\n\\n\"\n",
    "                               f\"UX Research: {ux_response}\\n\\n\"\n",
    "                            f\"Statistical Requirements: {stats_analysis}\"\n",
    "                            f\"Architecture and effort estimate: {arch_design}\", \n",
    "                            num_reflections=num_reflections)\n",
    "ux_ok, ux_memory_id = ux_researcher(f\"Are you okay with these user stories and acceptance criteria?:\\n\\n{user_stories}\",num_reflections=num_reflections)\n",
    "stats_ok, stats_memory_id = statistician(f\"Are the statistical requirements feasible given these user stories?:\\n\\n{user_stories}\",num_reflections=num_reflections)\n",
    "arch_ok, arch_memory_id = lead_architect(f\"Is the architecture feasible given these user stories and acceptance criteria?:\\n\\n{user_stories}\",num_reflections=num_reflections)\n",
    "#print(remove_markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda2200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î Reflecting 2 time(s)...\n",
      "ü§î Reflecting 2 time(s)...\n",
      "ü§î Reflecting 2 time(s)...\n"
     ]
    }
   ],
   "source": [
    "strategy_prompt, memory_id = pm_agent(f\"Please provide me with a prompt that summarizes the overall product plan, UX research, statistical requirements, architecture design, and roadmap that I can input to a tool called Gamma which generate powerpoints using GenAI:\\n\\n\"\n",
    "                               f\"Product Plan: {response}\\n\\n\"\n",
    "                               f\"UX Research: {ux_response}\\n\\n\"\n",
    "                            f\"Statistical Requirements: {stats_analysis}\"\n",
    "                            f\"Architecture and effort estimate: {arch_design}\"\n",
    "                            f\"User Stories and Acceptance Criteria: {user_stories}\"\n",
    "                            f\"UX Researcher Approval: {ux_ok}\"\n",
    "                            f\"Statistician Approval: {stats_ok}\"\n",
    "                            f\"Architect Approval: {arch_ok}\", \n",
    "                            num_reflections=num_reflections)\n",
    "\n",
    "engg_driven_prompt, memory_id = lead_architect(f\"\"\"Your task is to generate a single, comprehensive prompt that can be fed into Google AIStudio. \n",
    "This prompt should synthesize the following inputs into a coherent specification for prototype generation using GenAI/vibecoding:\n",
    "\n",
    "- Overall Product Plan\n",
    "- UX Research\n",
    "- Statistical Requirements\n",
    "- Architecture Design and Effort Estimate\n",
    "- User Stories and Acceptance Criteria\n",
    "- Approvals (UX Researcher, Statistician, Architect)\n",
    "\n",
    "When constructing the AIStudio prompt:\n",
    "1. Integrate all inputs into a structured, readable format that AIStudio can consume directly.\n",
    "2. Explicitly require that the prototype be responsive across both web and mobile platforms.\n",
    "3. Frame the output requirements so AIStudio generates a functional, interpretable, and extensible prototype.\n",
    "4. Ensure the synthesized prompt emphasizes alignment with product goals, UX findings, statistical rigor, architectural scalability, and roadmap milestones.\n",
    "\n",
    "Deliver the final output as a single, well‚Äëformed prompt ready to be passed into AIStudio.\n",
    "\\n\\n\"\"\"\n",
    "                               f\"Product Plan: {response}\\n\\n\"\n",
    "                               f\"UX Research: {ux_response}\\n\\n\"\n",
    "                            f\"Statistical Requirements: {stats_analysis}\"\n",
    "                            f\"Architecture and effort estimate: {arch_design}\"\n",
    "                            f\"User Stories and Acceptance Criteria: {user_stories}\"\n",
    "                            f\"UX Researcher Approval: {ux_ok}\"\n",
    "                            f\"Statistician Approval: {stats_ok}\"\n",
    "                            f\"Architect Approval: {arch_ok}\", \n",
    "                            num_reflections=num_reflections)\n",
    "\n",
    "pm_driven_prompt, memory_id = pm_agent(f\"\"\"Your task is to generate a single, comprehensive prompt that can be fed into Google AIStudio. \n",
    "This prompt should synthesize the following inputs into a coherent specification for prototype generation using GenAI/vibecoding:\n",
    "\n",
    "- Overall Product Plan\n",
    "- UX Research\n",
    "- Statistical Requirements\n",
    "- Architecture Design and Effort Estimate\n",
    "- User Stories and Acceptance Criteria\n",
    "- Approvals (UX Researcher, Statistician, Architect)\n",
    "\n",
    "When constructing the AIStudio prompt:\n",
    "1. Integrate all inputs into a structured, readable format that AIStudio can consume directly.\n",
    "2. Explicitly require that the prototype be responsive across both web and mobile platforms.\n",
    "3. Frame the output requirements so AIStudio generates a functional, interpretable, and extensible prototype.\n",
    "4. Ensure the synthesized prompt emphasizes alignment with product goals, UX findings, statistical rigor, architectural scalability, and roadmap milestones.\n",
    "\n",
    "Deliver the final output as a single, well‚Äëformed prompt ready to be passed into AIStudio.\n",
    "\\n\\n\"\"\"\n",
    "                               f\"Product Plan: {response}\\n\\n\"\n",
    "                               f\"UX Research: {ux_response}\\n\\n\"\n",
    "                            f\"Statistical Requirements: {stats_analysis}\"\n",
    "                            f\"Architecture and effort estimate: {arch_design}\"\n",
    "                            f\"User Stories and Acceptance Criteria: {user_stories}\"\n",
    "                            f\"UX Researcher Approval: {ux_ok}\"\n",
    "                            f\"Statistician Approval: {stats_ok}\"\n",
    "                            f\"Architect Approval: {arch_ok}\", \n",
    "                            num_reflections=num_reflections)\n",
    "\n",
    "ux_driven_prompt, ux_memory_id = ux_researcher(f\"\"\"Your task is to generate a single, comprehensive prompt that can be fed into Google AIStudio. \n",
    "This prompt should synthesize the following inputs into a coherent specification for prototype generation using GenAI/vibecoding:\n",
    "\n",
    "- Overall Product Plan\n",
    "- UX Research\n",
    "- Statistical Requirements\n",
    "- Architecture Design and Effort Estimate\n",
    "- User Stories and Acceptance Criteria\n",
    "- Approvals (UX Researcher, Statistician, Architect)\n",
    "\n",
    "When constructing the AIStudio prompt:\n",
    "1. Integrate all inputs into a structured, readable format that AIStudio can consume directly.\n",
    "2. Explicitly require that the prototype be responsive across both web and mobile platforms.\n",
    "3. Frame the output requirements so AIStudio generates a functional, interpretable, and extensible prototype.\n",
    "4. Ensure the synthesized prompt emphasizes alignment with product goals, UX findings, statistical rigor, architectural scalability, and roadmap milestones.\n",
    "\n",
    "Deliver the final output as a single, well‚Äëformed prompt ready to be passed into AIStudio.\n",
    "\\n\\n\"\"\"\n",
    "                               f\"Product Plan: {response}\\n\\n\"\n",
    "                               f\"UX Research: {ux_response}\\n\\n\"\n",
    "                            f\"Statistical Requirements: {stats_analysis}\"\n",
    "                            f\"Architecture and effort estimate: {arch_design}\"\n",
    "                            f\"User Stories and Acceptance Criteria: {user_stories}\"\n",
    "                            f\"UX Researcher Approval: {ux_ok}\"\n",
    "                            f\"Statistician Approval: {stats_ok}\"\n",
    "                            f\"Architect Approval: {arch_ok}\", \n",
    "                            num_reflections=num_reflections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c036f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course. This is the critical next step: translating our comprehensive strategic plan for \"The Deal Room\" into a well-defined, sprint-ready backlog for the engineering team.\n",
      "\n",
      "Based on our detailed product plan, V1 PRD, and the specific, actionable feedback from UX research, statistical analysis, and architecture, I have synthesized and refined the user stories. This backlog directly incorporates the key recommendations from our cross-functional partners and the improvements identified in our reflection. It includes agile best practices like a pre-development \"Spike\" for high-risk items and dedicated stories for all user journeys, including empty states.\n",
      "\n",
      "Before we dive in, a note on our process: this backlog represents the \"what\" and the \"why.\" To ensure quality and alignment, every story must meet our **Definition of Ready** (e.g., designs attached in Figma, acceptance criteria finalized) before being brought into a sprint. Upon completion, it must meet our **Definition of Done** (e.g., code peer-reviewed, automated tests passed, deployed to staging, and validated by QA).\n",
      "\n",
      "---\n",
      "\n",
      "### **Part 1: The Product Strategy & Roadmap (Refined)**\n",
      "\n",
      "*This is the strategic context for the backlog. It remains largely the same, but incorporates one key clarification based on our reflection.*\n",
      "\n",
      "#### **1. Phase 1 PRD: \"The Deal Room\"**\n",
      "\n",
      "*   **Key Personas:**\n",
      "    *   **User Persona:** \"The Orchestrator AE\"‚Äîan experienced enterprise sales professional managing deals >$100k ACV.\n",
      "    *   **Buyer Persona:** \"The VP of Sales\"‚Äîneeds visibility into operational blockers stalling their team's most important deals.\n",
      "*   **Problem Statement:** Enterprise AEs waste time context-switching between the CRM, email, and Slack to coordinate with internal teams, leading to deal delays and unreliable forecasting.\n",
      "*   **Core Hypothesis:** By providing a unified \"Deal Room\" that syncs with the CRM and provides a simple, shared task list for all internal stakeholders, we can reduce AE administrative time and give VPs of Sales unprecedented visibility into deal execution.\n",
      "*   **V1 Success Metrics (KPIs):**\n",
      "    *   **Adoption (Primary):** >30% of an AE's active deals are managed using a \"Deal Room.\"\n",
      "    *   **Engagement (Secondary):** >50% of Deal Rooms have at least one active non-sales stakeholder.\n",
      "    *   **Value (Leading):** NPS score > 45.\n",
      "*   **V1 Non-Goals (Disciplined Exclusion):**\n",
      "    *   We will **not** build complex Gantt charts or resource management.\n",
      "    *   We will **not** build customer-facing features.\n",
      "    *   We will **not** build a standalone mobile app (V1 is a responsive web app).\n",
      "    *   We will **not** build any AI-powered suggestions.\n",
      "    *   We will **not** include file attachments for tasks. This is a deliberate exclusion to maintain V1 simplicity and will be a fast-follow candidate for V2.\n",
      "\n",
      "---\n",
      "\n",
      "### **Part 2: The V1 Execution Plan (User Stories)**\n",
      "\n",
      "*This is the production-ready backlog, incorporating all feedback for clarity, completeness, and risk mitigation.*\n",
      "\n",
      "#### **Epic: Foundational & Non-Functional Requirements**\n",
      "\n",
      "*These are the critical technical stories that enable all user-facing features and ensure the product is secure, scalable, and measurable. We tackle these first to de-risk the project.*\n",
      "\n",
      "**Story 0: Spike - Investigate CRM Sync Strategy**\n",
      "*   **As the** engineering team,\n",
      "*   **we need to** investigate the target CRM's API limitations, data models, and authentication patterns,\n",
      "*   **so that we** can finalize the technical design for a reliable and performant sync service.\n",
      "    **Acceptance Criteria:**\n",
      "    *   Document API rate limits and recommended best practices for the chosen CRM (e.g., Salesforce).\n",
      "    *   Create a data mapping diagram between the CRM Opportunity object and our internal `deals` model.\n",
      "    *   Produce a recommendation on a polling vs. webhook strategy for V1.\n",
      "    *   This investigation is time-boxed to 3 days.\n",
      "\n",
      "**Story 1: Secure User Authentication**\n",
      "*   **As a** user,\n",
      "*   **I want to** be able to sign up and log in securely,\n",
      "*   **so that** I know my account and data are protected.\n",
      "    **Acceptance Criteria:**\n",
      "    *   Passwords are securely hashed (e.g., Argon2).\n",
      "    *   The application implements standard features like password complexity rules and a secure reset flow.\n",
      "    *   Sessions are managed via secure, short-lived tokens (e.g., JWTs).\n",
      "\n",
      "**Story 1.1: Manage Account Settings**\n",
      "*   **As a** user,\n",
      "*   **I want** a single \"Account Settings\" page,\n",
      "*   **so that** I can manage my profile, notifications, and integrations in one place.\n",
      "    **Acceptance Criteria:**\n",
      "    *   The page is accessible from the main navigation menu.\n",
      "    *   It includes a section for managing notification preferences (as required by Story 10).\n",
      "    *   It includes a section for managing the CRM connection status, including the ability to disconnect (as required by Story 4).\n",
      "\n",
      "**Story 1.2: Design for Empty States**\n",
      "*   **As the** product team,\n",
      "*   **we need to** define the UI for all primary \"empty state\" scenarios,\n",
      "*   **so that** the user experience feels polished and guides the user on what to do next.\n",
      "    **Acceptance Criteria:**\n",
      "    *   A defined empty state exists for the main deal list while the initial CRM sync is in progress.\n",
      "    *   A defined empty state exists for a new Deal Room before any tasks have been created.\n",
      "    *   A defined empty state exists for a Stakeholder's dashboard if they have not yet been invited to any Deal Rooms.\n",
      "\n",
      "**Story 2: Product Analytics Instrumentation**\n",
      "*   **As the** product team,\n",
      "*   **we need to** track key user actions via an analytics platform,\n",
      "*   **so that we** can measure our V1 KPIs and make data-informed decisions.\n",
      "    **Acceptance Criteria:**\n",
      "    *   The following events are tracked: `User Signed Up`, `CRM Connected`, `Deal Room Created`, `Stakeholder Invited`, `Task Completed`.\n",
      "    *   Event properties are included where relevant (e.g., `Deal Room Created` includes `template_used`).\n",
      "    *   Dashboards are created in our analytics tool to monitor V1 KPIs in real-time.\n",
      "\n",
      "---\n",
      "\n",
      "#### **Epic: Onboarding & CRM Integration**\n",
      "\n",
      "*This epic focuses on a frictionless first-time user experience (FTUE) for our primary persona and creating a seamless connection to the CRM.*\n",
      "\n",
      "**Story 3: First-Time AE Onboarding Experience**\n",
      "*   **As an** Account Executive (AE) signing in for the first time,\n",
      "*   **I want** a brief, guided onboarding experience,\n",
      "*   **so that** I understand the core value of the product and can get started in under 2 minutes.\n",
      "    **Acceptance Criteria:**\n",
      "    *   Upon first login, the user is shown a single welcome screen that briefly explains the \"Deal Room\" concept.\n",
      "    *   The primary call-to-action is \"Connect your CRM.\"\n",
      "    *   After connecting the CRM, a tooltip points the user to the \"Create Deal Room\" button on their first synced deal.\n",
      "\n",
      "**Story 4: Connect to CRM**\n",
      "*   **As an** AE,\n",
      "*   **I want to** securely connect my account to our company's CRM,\n",
      "*   **so that** the application can access my deal data.\n",
      "    **Acceptance Criteria:**\n",
      "    *   The connection process uses a secure OAuth 2.0 flow.\n",
      "    *   Once connected, the connection status is clearly visible on the Account Settings page.\n",
      "    *   If the connection fails or the user cancels, a clear error message is displayed with a retry option.\n",
      "    *   The user can disconnect their CRM account at any time via the Account Settings page.\n",
      "\n",
      "**Story 5: Initial & Ongoing Deal Sync**\n",
      "*   **As an** AE,\n",
      "*   **I want** all of my relevant deals from the CRM to be automatically synced,\n",
      "*   **so that** I have a complete and accurate list to create Deal Rooms for.\n",
      "    **Acceptance Criteria:**\n",
      "    *   Upon successful CRM connection, the system performs an initial sync of all opportunities owned by the user, including those with **'Open,' 'Closed-Won,' and 'Closed-Lost' statuses** to prevent survivorship bias for our future analytics.\n",
      "    *   The main dashboard defaults to showing 'Open' deals, but provides clear and easy-to-use filters for 'All,' 'Closed-Won,' and 'Closed-Lost' statuses.\n",
      "    *   Deal data is updated from the CRM in near real-time (latency <5 minutes).\n",
      "\n",
      "**Story 5.1: Search and Filter Deals on Dashboard**\n",
      "*   **As an** AE with many active deals,\n",
      "*   **I want to** be able to search my deal list by name,\n",
      "*   **so that** I can quickly find the specific deal I want to work on.\n",
      "    **Acceptance Criteria:**\n",
      "    *   A search input field is present above the deal list on the main dashboard.\n",
      "    *   As the user types, the list of deals filters in real-time to show only deals whose name contains the search term.\n",
      "    *   The search works in conjunction with the existing status filters.\n",
      "\n",
      "---\n",
      "\n",
      "#### **Epic: The Deal Room Workspace**\n",
      "\n",
      "*This epic covers the core value proposition for the AE: creating and managing a dedicated workspace for each complex deal.*\n",
      "\n",
      "**Story 6: Create a Deal Room**\n",
      "*   **As an** AE,\n",
      "*   **I want to** create a \"Deal Room\" from any of my synced CRM deals,\n",
      "*   **so that** I can start managing cross-functional tasks.\n",
      "    **Acceptance Criteria:**\n",
      "    *   Every deal in the synced deal list has a \"Create Deal Room\" button.\n",
      "    *   The user can optionally apply a pre-defined template during creation.\n",
      "    *   Once created, the user is taken to the Deal Room's main view.\n",
      "\n",
      "**Story 7: View and Manage Tasks in a Deal Room**\n",
      "*   **As an** AE,\n",
      "*   **I want** a simple task list within a Deal Room,\n",
      "*   **so that** I can track the status of all moving parts of my deal.\n",
      "    **Acceptance Criteria:**\n",
      "    *   The Deal Room features a simple to-do list interface (not a Gantt chart).\n",
      "    *   The AE can create tasks with a title, optional description, an assignee, and a due date.\n",
      "    *   Tasks have statuses (e.g., \"To Do,\" \"In Progress,\" \"Done\").\n",
      "\n",
      "---\n",
      "\n",
      "#### **Epic: Cross-Functional Collaboration**\n",
      "\n",
      "*This epic focuses on our key differentiator: securely bringing non-sales team members into the deal process.*\n",
      "\n",
      "**Story 8: Invite & Manage Stakeholders**\n",
      "*   **As an** AE,\n",
      "*   **I want to** invite and manage internal stakeholders in a specific Deal Room,\n",
      "*   **so that** I can assign tasks to them and control access.\n",
      "    **Acceptance Criteria:**\n",
      "    *   The Deal Room has an \"Invite\" feature where the AE can add users by email.\n",
      "    *   Invited users receive an email prompting them to sign up.\n",
      "    *   The AE can see a list of all members of a Deal Room and remove them.\n",
      "    *   When inviting a new user, their role within that Deal Room is automatically set to 'Stakeholder'. The AE who created the room has the 'Owner' role.\n",
      "\n",
      "**Story 8.1: Onboard as an Invited Stakeholder**\n",
      "*   **As a** newly invited Stakeholder,\n",
      "*   **I want** a lightweight sign-up that takes me directly to the relevant Deal Room,\n",
      "*   **so that** I can immediately understand the context and act on my assigned task.\n",
      "    **Acceptance Criteria:**\n",
      "    *   The sign-up flow for an invited user does not prompt to connect a CRM.\n",
      "    *   Upon first login, the user is taken directly to the Deal Room they were invited to.\n",
      "    *   A tooltip briefly explains their limited role and points out their assigned task.\n",
      "\n",
      "**Story 9: Stakeholder Limited View**\n",
      "*   **As a** non-sales Stakeholder (e.g., a lawyer),\n",
      "*   **I want to** see only the specific Deal Rooms and tasks I've been invited to,\n",
      "*   **so that** I can focus on my work without being overwhelmed.\n",
      "    **Acceptance Criteria:**\n",
      "    *   A stakeholder's dashboard only lists Deal Rooms they are a member of.\n",
      "    *   Within a Deal Room, a stakeholder can only edit tasks assigned to them.\n",
      "    *   **Crucially**, the API response for the deal **must not** contain sensitive fields like `deal_amount` or `forecast_category` for users with a 'Stakeholder' role.\n",
      "\n",
      "**Story 10: Task Notifications**\n",
      "*   **As a** Stakeholder,\n",
      "*   **I want to** receive a notification when I am assigned a new task,\n",
      "*   **so that** I can stay on top of my responsibilities.\n",
      "    **Acceptance Criteria:**\n",
      "    *   An email notification is sent when a task is assigned to a user.\n",
      "    *   The email contains a direct link to the task within the Deal Room.\n",
      "    *   Users can manage their notification preferences on the Account Settings page.\n",
      "\n",
      "---\n",
      "\n",
      "#### **Epic: Templates & Process Standardization**\n",
      "\n",
      "*This epic helps AEs be more efficient and encourages best practices.*\n",
      "\n",
      "**Story 11: Use a Deal Room Template**\n",
      "*   **As an** AE,\n",
      "*   **I want to** create a Deal Room from a template (e.g., \"Security Review\"),\n",
      "*   **so that** it is instantly populated with standard tasks.\n",
      "    **Acceptance Criteria:**\n",
      "    *   The \"Create Deal Room\" flow allows selecting from a list of templates.\n",
      "    *   Templates are pre-configured with a list of standard tasks.\n",
      "    *   The V1 product ships with at least three templates based on user research (\"Security Review,\" \"POC Management,\" etc.).\n",
      "\n",
      "**Story 12: Admin Manages V1 Templates**\n",
      "*   **As an** Application Administrator,\n",
      "*   **I need** a basic interface (e.g., the Django Admin Panel),\n",
      "*   **so that** I can create, edit, and manage the system-wide templates available to all users for V1.\n",
      "    **Acceptance Criteria:**\n",
      "    *   An admin user can log into a secure admin interface.\n",
      "    *   From the interface, the admin can create a new template with a name and description.\n",
      "    *   The admin can add, edit, and remove task definitions (title, default role) associated with a template.\n",
      "    *   These templates are immediately available for selection in the \"Create a Deal Room\" flow.\n"
     ]
    }
   ],
   "source": [
    "print(strategy_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b155c166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course. Based on our comprehensive product strategy, the detailed V1 execution plan, and the critical feedback from our cross-functional partners and internal reflections, I am providing a complete system architecture and development plan for \"The Deal Room.\"\n",
      "\n",
      "This plan is engineered to deliver the focused V1 described in the user stories while creating the essential technical foundation for the ambitious V2/V3 roadmap. It directly incorporates the non-negotiable requirements for multi-tenancy, a limited stakeholder view, functional templates, and a causal-ready data model.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. System Architecture Overview\n",
      "\n",
      "The V1 architecture will be a **pragmatic, well-structured monolith** deployed on AWS. This approach prioritizes V1 development speed and simplicity, which is ideal for validating our core product hypotheses. The architecture is designed with clear logical boundaries that will allow for future decomposition into microservices once the product is validated and scaling becomes a primary concern. The core principle is the strict separation of the application's main synchronous API workload from high-latency, asynchronous processes like CRM synchronization and notifications.\n",
      "\n",
      "**High-Level Architecture Diagram (AWS Specific):**\n",
      "\n",
      "```\n",
      "+--------------+     +-----------------+     +--------------------------+\n",
      "|  Web Client  |---->| AWS API Gateway |---->|   Backend Service        |\n",
      "|   (React)    |     | (Auth & Routing)|     |   (Python/Django)        |\n",
      "| (S3/CloudFront) |<-|                 |<----|   (on AWS Fargate)       |\n",
      "+--------------+     +-----------------+     +-----------+--------------+\n",
      "                                                         | (Write to SQS)\n",
      "                                                +--------v--------------+\n",
      "                                                |                       |\n",
      "                                                | Transactional DB (OLTP)|\n",
      "+-------------------+                           | (PostgreSQL on RDS)   |\n",
      "| 3rd Party         |                           | (Multi-Tenant Schema) |\n",
      "| CRM (e.g., SFDC)  |<---------------------+    +-----------------------+\n",
      "+-------------------+                      |\n",
      "         ^                                 | (Read/Write)\n",
      "         | (API Calls)                     |\n",
      "+--------|------------------------+        |\n",
      "|        v                        |        |\n",
      "|  CRM Sync Worker (Celery)       |<-------+\n",
      "|  (on AWS Fargate)               |\n",
      "|  [Triggered by SQS Queue]       |\n",
      "+---------------------------------+\n",
      "```\n",
      "\n",
      "**Key Components:**\n",
      "*   **Web Client (React):** A modern Single-Page Application (SPA) that implements the user-facing acceptance criteria for all epics. It will be hosted as a static site on **AWS S3** and served globally via **AWS CloudFront** for low latency, high availability, and decoupled deployment from the backend.\n",
      "*   **API Gateway (AWS API Gateway):** A managed service serving as the secure entry point for all API calls. It handles JWT validation (**Story 1**), rate limiting, and request routing to the backend service.\n",
      "*   **Backend Service (Python/Django on AWS Fargate):** Contains the core business logic. It handles multi-tenant account creation (**Story 1**), creating Deal Rooms (**Story 6**), managing tasks (**Story 7**), and, most critically, enforcing the granular permissions required by **Story 9**.\n",
      "*   **CRM Sync Worker (Celery on AWS Fargate):** A logically separate, queue-based worker process. It is solely responsible for all communication with the third-party CRM API (**Stories 4 & 5**). The output of the **Spike (Story 0)** will directly determine its final implementation. Decoupling via an SQS queue is essential for resilience.\n",
      "*   **Transactional Database (PostgreSQL on AWS RDS):** The primary data store for the application, designed with a multi-tenant, \"causal-ready\" schema from day one.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Technology Stack\n",
      "\n",
      "The stack is chosen for developer productivity, a strong ecosystem for integrations, security, and its explicit alignment with the long-term data science vision (V3).\n",
      "\n",
      "*   **Frontend:** **React** with **TypeScript**.\n",
      "    *   **Justification:** The industry standard for complex SPAs. TypeScript is crucial for building a maintainable application, especially when handling complex data models and enforcing different views for user roles.\n",
      "*   **Backend:** **Python** with the **Django Framework**.\n",
      "    *   **Justification:** Python is the premier language for data science, making it the perfect choice for the V3 vision. Django's \"batteries-included\" nature will significantly accelerate V1 development.\n",
      "*   **Database (Transactional):** **PostgreSQL (via AWS RDS)**.\n",
      "    *   **Justification:** A highly reliable, open-source RDBMS. Its `JSONB` support is ideal for storing the flexible metadata required for our \"causal-ready\" schema.\n",
      "*   **Infrastructure:** **Amazon Web Services (AWS)** managed with **Terraform**.\n",
      "    *   **Justification:** AWS provides a mature, secure, and scalable ecosystem. Managing infrastructure as code (IaC) with Terraform ensures our environments are reproducible and version-controlled.\n",
      "*   **Code Quality & Testing Strategy:**\n",
      "    *   **CI/CD:** We will establish a CI/CD pipeline using **GitHub Actions** that automates testing, security scanning (e.g., Snyk), and deployments to our `staging` and `production` environments.\n",
      "    *   **Backend Testing:** **Pytest** for unit and integration tests, aiming for >80% code coverage on core business logic.\n",
      "    *   **Frontend Testing:** **Jest & React Testing Library** for component unit tests.\n",
      "    *   **End-to-End Testing:** A small suite of **Cypress** tests will cover critical user flows (e.g., AE invites stakeholder, stakeholder completes task).\n",
      "*   **Analytics:** **Segment** to route events tracked in **Story 2** to product analytics tools (e.g., Amplitude) and our data warehouse.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Data Architecture\n",
      "\n",
      "This data architecture is designed from day one to be **multi-tenant, \"causal-ready,\"** and fully capable of supporting all V1 user stories.\n",
      "\n",
      "**Database Schema (Refined PostgreSQL):**\n",
      "```sql\n",
      "-- The root of our multi-tenancy model.\n",
      "CREATE TABLE organizations (\n",
      "    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
      "    name VARCHAR(255) NOT NULL\n",
      ");\n",
      "\n",
      "-- Users are globally unique by email.\n",
      "CREATE TABLE users (\n",
      "    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
      "    email VARCHAR(255) UNIQUE NOT NULL,\n",
      "    password_hash VARCHAR(255) NOT NULL,\n",
      "    status VARCHAR(50) NOT NULL DEFAULT 'active' -- 'active', 'invited'\n",
      ");\n",
      "\n",
      "CREATE TABLE organization_members (\n",
      "    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n",
      "    organization_id UUID NOT NULL REFERENCES organizations(id) ON DELETE CASCADE,\n",
      "    role VARCHAR(50) NOT NULL DEFAULT 'sales_user', -- 'admin', 'sales_user'\n",
      "    PRIMARY KEY (user_id, organization_id)\n",
      ");\n",
      "\n",
      "-- ALL deals from the CRM (won, lost, open) to avoid survivorship bias.\n",
      "CREATE TABLE deals (\n",
      "    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
      "    organization_id UUID NOT NULL REFERENCES organizations(id),\n",
      "    crm_id VARCHAR(255) NOT NULL,\n",
      "    status VARCHAR(50) NOT NULL, -- 'Open', 'Closed-Won', 'Closed-Lost'\n",
      "    crm_metadata JSONB, -- For potential confounders\n",
      "    UNIQUE(organization_id, crm_id)\n",
      ");\n",
      "\n",
      "-- The core \"Deal Room\" which defines our treatment group.\n",
      "CREATE TABLE deal_rooms (\n",
      "    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
      "    deal_id UUID UNIQUE NOT NULL REFERENCES deals(id) ON DELETE CASCADE\n",
      ");\n",
      "\n",
      "-- Defines membership and permissions within a specific room.\n",
      "CREATE TABLE deal_room_members (\n",
      "    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n",
      "    deal_room_id UUID NOT NULL REFERENCES deal_rooms(id) ON DELETE CASCADE,\n",
      "    role VARCHAR(50) NOT NULL DEFAULT 'stakeholder', -- 'owner', 'stakeholder'\n",
      "    PRIMARY KEY (user_id, deal_room_id)\n",
      ");\n",
      "\n",
      "-- Tasks within a Deal Room (Story 7).\n",
      "CREATE TABLE tasks ( /* ... as defined in previous responses ... */ );\n",
      "\n",
      "-- The immutable event stream for future causal analysis.\n",
      "CREATE TABLE audit_events (\n",
      "    id BIGSERIAL PRIMARY KEY,\n",
      "    organization_id UUID NOT NULL,\n",
      "    user_id UUID,\n",
      "    event_type VARCHAR(100) NOT NULL,\n",
      "    event_data JSONB,\n",
      "    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()\n",
      ");\n",
      "```\n",
      "**User Invitation Flow:** When an AE invites an email address not present in the `users` table, a placeholder record is created with a `status` of 'invited'. An email is sent with a secure, time-limited sign-up token. Upon completion of the sign-up form, the user record `status` is changed to 'active', the password hash is set, and they are automatically added to the correct `deal_room_members` table.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. API Design\n",
      "\n",
      "We will use a standard RESTful API for V1, secured with short-lived JWTs. The API contract will be defined upfront using the **OpenAPI 3.0 (Swagger)** specification to enable parallel development.\n",
      "\n",
      "*   `POST /api/v1/auth/register` (**Story 1**)\n",
      "*   `GET /api/v1/deals` (**Story 5**)\n",
      "*   `POST /api/v1/deals/{deal_id}/rooms` (**Story 6**)\n",
      "*   `POST /api/v1/rooms/{room_id}/members` (**Story 8**)\n",
      "*   `POST /api/v1/rooms/{room_id}/tasks` (**Story 7**)\n",
      "*   `PATCH /api/v1/tasks/{task_id}` (**Story 7**)\n",
      "*   **Pagination:** All list endpoints (e.g., `GET /api/v1/deals`) will implement a standard offset/limit pagination strategy from Day 1 to ensure performance and prevent excessive data transfer.\n",
      "\n",
      "---\n",
      "\n",
      "### 5. Security & Compliance\n",
      "\n",
      "*   **Authentication (Story 1):** User passwords securely hashed with **Argon2**. APIs require a valid, short-lived JWT containing `user_id` and `organization_id`.\n",
      "*   **Authorization (Story 9 & Multi-Tenancy):**\n",
      "    1.  **Tenant Isolation:** All database queries are strictly filtered by the `organization_id` from the user's JWT, enforced in a reusable data access layer to prevent leaks.\n",
      "    2.  **Role-Based Access Control (RBAC):** For a specific resource, the API checks the user's role in `deal_room_members`. Authorization is enforced in a single, reusable middleware layer.\n",
      "*   **Secret Management:** All secrets (database credentials, API keys) will be managed using **AWS Secrets Manager**. Application services will retrieve these secrets at runtime via IAM roles, ensuring no secrets are stored in code.\n",
      "*   **Observability:** We will implement structured JSON logging across all services aggregated in **AWS CloudWatch Logs**. Key metrics will be sent to **CloudWatch Metrics**, and **Sentry** will be used for real-time exception tracking.\n",
      "\n",
      "---\n",
      "\n",
      "### 6. Development Plan\n",
      "\n",
      "We will use a sprint-based agile methodology (2-week sprints) designed to de-risk the project by tackling the largest unknowns first.\n",
      "\n",
      "*   **Sprint 0: De-risking & Foundation**\n",
      "    *   **Focus:** Tackle the biggest unknown. Define the OpenAPI contract.\n",
      "    *   **Stories:** #0 (Spike for CRM Sync).\n",
      "    *   **Milestone:** **Go/No-Go Checkpoint.** Review spike findings and re-evaluate project timeline before proceeding.\n",
      "*   **Sprints 1-2: Core Platform & Multi-Tenancy**\n",
      "    *   **Focus:** Build the application skeleton, security, and analytics.\n",
      "    *   **Stories:** #1 (User Auth w/ multi-tenancy), #2 (Analytics), CI/CD setup.\n",
      "*   **Sprints 3-5: CRM Integration & Onboarding**\n",
      "    *   **Focus:** Implement the highest-risk feature.\n",
      "    *   **Stories:** #3, #8.1 (Onboarding), #4 (CRM Connect), #5 (Deal Sync - *modified to include won/lost deals*).\n",
      "*   **Sprints 6-8: The Core Value Prop**\n",
      "    *   **Focus:** Build the Deal Room and task management features.\n",
      "    *   **Stories:** #6 (Create Room), #7 (Manage Tasks), #11 (Templates).\n",
      "*   **Sprints 9-10: Collaboration & Polish**\n",
      "    *   **Focus:** Enable cross-functional work and prepare for beta.\n",
      "    *   **Stories:** #8 (Invite/Manage), #9 (Limited View), #10 (Notifications).\n",
      "\n",
      "---\n",
      "\n",
      "### 7. Effort Estimates\n",
      "\n",
      "The estimates remain credible as these refinements focus on best practices rather than scope expansion.\n",
      "\n",
      "*   **Total V1 Estimate:** **120 Story Points.**\n",
      "*   **Contingency & Timeline:** With a **20% contingency buffer**, the planning budget is **~144 Story Points**. This translates to a realistic timeline of **10-11 sprints (20-22 weeks)** for a focused team of 5 engineers.\n",
      "\n",
      "---\n",
      "\n",
      "### 8. Technical Risks\n",
      "\n",
      "1.  **CRM Integration Complexity:**\n",
      "    *   **Risk:** The chosen CRM's API is unreliable, has restrictive rate limits, or is poorly documented. This remains the **highest technical risk**.\n",
      "    *   **Mitigation:** The **Spike in Story 0** and Go/No-Go checkpoint are our primary mitigations. The async, queue-based architecture with robust Sentry monitoring provides operational resilience.\n",
      "2.  **Authorization Logic Errors:**\n",
      "    *   **Risk:** A bug in our RBAC or multi-tenancy implementation accidentally exposes data, either sensitive deal info to a stakeholder (violating **Story 9**) or data from another organization.\n",
      "    *   **Mitigation:** A multi-layered defense: extensive automated tests for permissions logic; enforce authorization at a single, reusable middleware layer; conduct rigorous peer reviews for any code that touches security.\n",
      "3.  **Data Integrity for Analytics:**\n",
      "    *   **Risk:** The CRM sync fails to capture all necessary deal statuses (`won`, `lost`) or key potential confounders, invalidating the dataset for the V3 vision.\n",
      "    *   **Mitigation:** The data schema and sync logic for **Story 5** will be designed in lockstep with our data/statistical experts. We will implement data profiling and quality checks during the sync process to monitor its health from day one.\n",
      "4.  **Stakeholder Experience Friction:**\n",
      "    *   **Risk:** The product is optimized for AEs, but the experience for invited stakeholders (Legal, Security) is clunky or requires too much effort, leading to poor adoption by this critical group.\n",
      "    *   **Mitigation:** This is primarily a UX risk. Mitigation includes dedicated usability testing with non-sales personas, ensuring the stakeholder view is ruthlessly simple, and implementing a frictionless \"magic link\" login process for invited users.\n"
     ]
    }
   ],
   "source": [
    "print(engg_driven_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dbf77162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course. Synthesizing our entire planning process into a single, comprehensive prompt for a generative AI tool like Google AIStudio is the perfect way to ensure all strategic, user-centric, and technical requirements are translated into a coherent prototype.\n",
      "\n",
      "Based on our collaborative work and the specific improvements identified during our reflection, I have generated an enhanced, production-grade prompt. This version provides greater technical specificity, incorporates accessibility as a core principle, and adds clear acceptance criteria for the prototype itself to ensure the AI's output is testable, extensible, and precisely aligned with our goals.\n",
      "\n",
      "---\n",
      "\n",
      "### **Prompt for Google AIStudio: High-Fidelity Prototype Generation for \"The Deal Room\"**\n",
      "\n",
      "**Objective:** Generate a high-fidelity, functional prototype for a new B2B SaaS product called \"The Deal Room.\" This prototype will serve as the primary tool for user testing, internal validation, and the foundational codebase for our V1 product.\n",
      "\n",
      "**Core Role:** You are an expert full-stack engineering team. Your task is to interpret this comprehensive product specification and build a clean, scalable, and responsive prototype using the specified technology stack. You must adhere to all principles and implement all user journeys and error states as described.\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Product Vision & Core Principles**\n",
      "\n",
      "*   **Vision:** To create the indispensable cross-functional workspace for complex B2B sales deals, moving teams from chaotic coordination to predictable execution. We are the \"action layer\" on top of the CRM, not a replacement for it.\n",
      "*   **Target User:** The \"Orchestrator AE\"‚Äîan Enterprise Account Executive managing large, multi-month deals.\n",
      "*   **Core Problem:** AEs waste hours context-switching between the CRM, email, and Slack to coordinate with internal teams like Legal and Security. This leads to deal delays and operational blindness for sales leaders.\n",
      "*   **V1 Solution (\"The Deal Room\"):** A unified, CRM-synced workspace for a single deal that provides a simple, shared task list for all internal stakeholders.\n",
      "*   **Key Design Principle:** **Simplicity over features.** Based on our \"Non-Goals,\" V1 is about nailing a simple, shared to-do list. Do NOT build Gantt charts, AI suggestions, or a separate mobile app. The entire user experience should feel intuitive and achievable in under 2 minutes.\n",
      "*   **Critical Security Principle:** **Granular Permissions are non-negotiable.** The AE must trust that non-sales stakeholders will *only* see information relevant to their tasks and will be firewalled from sensitive deal data (e.g., deal amount). This must be enforced at a simulated API level.\n",
      "*   **Data Integrity Principle:** The prototype must be architected with a \"causal-ready\" mindset for our V3 \"Revenue Intelligence Hub.\" Mock data and event tracking must account for both successful and unsuccessful outcomes to avoid **survivorship bias**.\n",
      "*   **Accessibility Principle:** The prototype must adhere to WCAG 2.1 AA standards. All interactive elements must be keyboard-navigable, and key components should have appropriate ARIA labels (e.g., Kanban columns announced as lists, tasks as list items).\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Technical & Platform Requirements**\n",
      "\n",
      "*   **Platform:** A responsive web application that provides a seamless experience on both desktop and mobile browsers.\n",
      "*   **Frontend:** React with TypeScript. Code must be component-based, clean, well-commented, and extensible to serve as a foundation for production.\n",
      "*   **UI/UX & Visual Style Guide:**\n",
      "    *   Implement using the **Ant Design** component library to ensure visual consistency.\n",
      "    *   **Primary Color:** Use `#4A90E2` for all primary buttons, links, and active states.\n",
      "    *   **Typography:** Use the 'Inter' font family for all text.\n",
      "    *   **Density:** The UI should feel spacious. Use a base padding of 16px for most components.\n",
      "*   **State Management:** Manage application state using React's Context API or a lightweight library like Zustand. Avoid prop-drilling to ensure the codebase is maintainable.\n",
      "*   **Mobile Responsiveness:** The UI must adapt cleanly to mobile viewports (<768px). Multi-column layouts should stack into a single, scrollable column. Primary navigation should collapse into a hamburger menu.\n",
      "*   **Backend (Simulated):** The prototype should function as if it is powered by a Python/Django backend API. All data should be managed in a client-side state that mimics API calls.\n",
      "*   **Database (Simulated):** The data structure must reflect a PostgreSQL database schema. Use the schema provided in Section 6 to inform your data models and mock data generation.\n",
      "*   **Authentication:** Implement a mock user authentication flow.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Personas & Mock Data**\n",
      "\n",
      "Generate mock data for two distinct user personas. The prototype must support logging in as either user to demonstrate role-based access control (RBAC).\n",
      "\n",
      "*   **Persona 1: Sarah, the Account Executive (AE)**\n",
      "    *   `user_id`: `a1b2c3d4-e5f6-7890-1234-567890abcdef`\n",
      "    *   Email: `sarah.ae@example.com`\n",
      "    *   Role: The primary user (\"owner\" or \"sales_user\"). She has full control over the Deal Rooms she creates.\n",
      "*   **Persona 2: David, the Legal Counsel (Stakeholder)**\n",
      "    *   `user_id`: `fedcba09-8765-4321-0987-654321fedcba`\n",
      "    *   Email: `david.legal@example.com`\n",
      "    *   Role: The secondary user (\"stakeholder\"). He has a limited, \"guest\" view.\n",
      "\n",
      "Generate a list of 15-20 mock CRM deals for Sarah. This data must include:\n",
      "*   Deal Name, Account Name, Deal Amount, Deal Stage.\n",
      "*   **Status:** To satisfy the **Data Integrity Principle**, include a mix of `Open`, `Closed-Won`, and `Closed-Lost` deals in the dataset.\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Core User Journeys & Feature Implementation**\n",
      "\n",
      "Implement the following user journeys based on the detailed user stories and acceptance criteria.\n",
      "\n",
      "#### **Journey 1: AE Onboarding & First Sync**\n",
      "*   **Authentication (Story 1):** Create a simple login page for `sarah.ae@example.com` and `david.legal@example.com`.\n",
      "*   **First-Time Onboarding (Story 3):** Upon Sarah's first login, present a single welcome screen explaining the \"Deal Room\" concept with a primary CTA: \"Connect your CRM.\"\n",
      "*   **CRM Connection (Story 4):** Clicking the CTA simulates a secure OAuth 2.0 flow. On success, show a confirmation and navigate to the dashboard.\n",
      "*   **Deal Sync & Dashboard (Story 5):** Sarah lands on her main dashboard. This is a list view of her mock deals. **Crucially, this view must default to showing only 'Open' deals but provide clear filters for 'All,' 'Closed-Won,' and 'Closed-Lost' statuses.** The list should show Deal Name, Account Name, Stage, and Amount.\n",
      "\n",
      "#### **Journey 2: Creating and Managing a Deal Room**\n",
      "*   **Create Deal Room (Story 6):** Each deal in Sarah's list has a \"Create Deal Room\" button.\n",
      "*   **Use a Template (Story 11):** This button opens a modal where Sarah can choose from templates. Selecting a template pre-populates the Deal Room with relevant tasks:\n",
      "    *   **\"Security Review\":** \"Schedule security call,\" \"Provide security docs,\" \"Complete vendor questionnaire,\" \"Get InfoSec sign-off.\"\n",
      "    *   **\"POC Management\":** \"Define success criteria with customer,\" \"Deploy POC environment,\" \"Schedule weekly check-in,\" \"Present POC findings.\"\n",
      "    *   **\"Standard Enterprise Deal\":** \"Draft MSA,\" \"Internal Pricing Approval,\" \"Send contract via DocuSign,\" \"Provision account.\"\n",
      "*   **Manage Tasks (Story 7):** The Deal Room view is a simple three-column Kanban board (\"To Do,\" \"In Progress,\" \"Done\"). It must support creating tasks with a title, description, assignee, and due date. Sarah can edit, delete, and filter all tasks.\n",
      "\n",
      "#### **Journey 3: The Critical Cross-Functional Collaboration Flow**\n",
      "*   **Invite Stakeholder (Story 8):** In a Deal Room, Sarah clicks an \"Invite\" button and enters `david.legal@example.com`.\n",
      "*   **Stakeholder Onboarding (Story 8.1):** Simulate a \"magic link\" login for David. He should land on a page that says \"You've been invited to the [Deal Name] Deal Room\" and can enter the prototype with a single click, bypassing the need for a password on first entry. He lands directly inside the Deal Room he was invited to, with a tooltip pointing out his assigned task.\n",
      "*   **Log out as David and log back in as Sarah to test the full flow.**\n",
      "*   **Stakeholder Limited View (Story 9 - CRITICAL IMPLEMENTATION):**\n",
      "    *   David's main dashboard only shows a list titled \"My Assigned Deal Rooms.\"\n",
      "    *   When David views a Deal Room, the header **must not** display sensitive CRM data (e.g., Deal Amount).\n",
      "    *   He can see all tasks for context, but can only edit or drag-and-drop tasks specifically assigned to him. All other tasks are read-only.\n",
      "*   **Notifications (Story 10):** Implement an in-app notification bell. When Sarah assigns a task to David, the bell on David's UI shows an indicator. He can manage notification preferences on a dedicated \"Account Settings\" page.\n",
      "\n",
      "---\n",
      "\n",
      "### **5. Error Handling & Unhappy Paths**\n",
      "\n",
      "A high-fidelity prototype must handle common errors gracefully. Implement the following:\n",
      "*   **CRM Connection Failure:** If the OAuth flow simulates a failure, display a non-modal error toast that says, \"Connection Failed. Please try again.\"\n",
      "*   **Invalid Invite:** In the \"Invite Stakeholder\" modal, if Sarah enters an invalid email format, show an inline validation error message.\n",
      "\n",
      "---\n",
      "\n",
      "### **6. Data Schema & Analytics Simulation**\n",
      "\n",
      "Use this simplified schema to structure your components' data models.\n",
      "```sql\n",
      "CREATE TABLE deals ( id UUID, crm_id VARCHAR, name VARCHAR, stage VARCHAR, amount DECIMAL, status VARCHAR );\n",
      "CREATE TABLE deal_rooms ( id UUID, deal_id UUID, template_used VARCHAR );\n",
      "CREATE TABLE deal_room_members ( deal_room_id UUID, user_id UUID, role VARCHAR ); -- role = 'owner' or 'stakeholder'\n",
      "CREATE TABLE tasks ( id UUID, deal_room_id UUID, title VARCHAR, description TEXT, status VARCHAR, assignee_id UUID, due_date TIMESTAMP );\n",
      "CREATE TABLE audit_events ( id BIGSERIAL, deal_id UUID, user_id UUID, event_type VARCHAR, event_data JSON, created_at TIMESTAMP );\n",
      "```\n",
      "\n",
      "**Analytics Instrumentation (Story 2):**\n",
      "To simulate our V1 measurement strategy, implement `console.log()` statements that match the `audit_events` schema.\n",
      "*   On sign-up: `console.log({ event_type: 'User Signed Up', event_data: { user_id: '...', role: '...' } });`\n",
      "*   On CRM connect: `console.log({ event_type: 'CRM Connected', event_data: { user_id: '...' } });`\n",
      "*   On room creation: `console.log({ event_type: 'Deal Room Created', event_data: { deal_id: '...', template_used: '...' } });`\n",
      "*   On invite: `console.log({ event_type: 'Stakeholder Invited', event_data: { deal_id: '...', invitee_id: '...' } });`\n",
      "*   On task completion: `console.log({ event_type: 'Task Completed', event_data: { deal_id: '...', task_id: '...' } });`\n",
      "\n",
      "---\n",
      "\n",
      "### **7. Final Output & Acceptance Criteria**\n",
      "\n",
      "Deliver a single, self-contained, and functional codebase for the prototype. The output should be a web application that can be run locally, demonstrating all specified journeys, the critical dual-persona permission model, error states, and simulated data/event logging. The code must be clean, commented, and organized into logical React components to serve as a strong foundation for V1 development.\n",
      "\n",
      "**Acceptance Criteria for Prototype:**\n",
      "The prototype will be considered successfully generated if:\n",
      "1.  A user can log in as both Sarah (AE) and David (Stakeholder) and experience their distinct user journeys, including David's \"magic link\" onboarding.\n",
      "2.  The end-to-end \"Cross-Functional Collaboration\" flow (Journey 3) can be completed without error, from invite to task completion.\n",
      "3.  The permissioning for the Stakeholder Limited View (Story 9) is correctly and rigorously enforced, hiding all sensitive deal data from David's view.\n",
      "4.  The application is fully responsive and accessible according to the principles defined in Section 1.\n"
     ]
    }
   ],
   "source": [
    "print(pm_driven_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2042e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î Reflecting 2 time(s)...\n"
     ]
    }
   ],
   "source": [
    "ux_driven_prompt, ux_memory_id = ux_researcher(f\"\"\"Your task is to generate a single, comprehensive prompt that can be fed into Google AIStudio. \n",
    "This prompt should synthesize the following inputs into a coherent specification for prototype generation using GenAI/vibecoding:\n",
    "\n",
    "- Overall Product Plan\n",
    "- UX Research\n",
    "- Statistical Requirements\n",
    "- Architecture Design and Effort Estimate\n",
    "- User Stories and Acceptance Criteria\n",
    "- Approvals (UX Researcher, Statistician, Architect)\n",
    "\n",
    "When constructing the AIStudio prompt:\n",
    "1. Integrate all inputs into a structured, readable format that AIStudio can consume directly.\n",
    "2. Explicitly require that the prototype be responsive across both web and mobile platforms.\n",
    "3. Frame the output requirements so AIStudio generates a functional, interpretable, and extensible prototype.\n",
    "4. Ensure the synthesized prompt emphasizes alignment with product goals, UX findings, statistical rigor, architectural scalability, and roadmap milestones.\n",
    "\n",
    "Deliver the final output as a single, well‚Äëformed prompt ready to be passed into AIStudio.\n",
    "\\n\\n\"\"\"\n",
    "                               f\"Product Plan: {response}\\n\\n\"\n",
    "                               f\"UX Research: {ux_response}\\n\\n\"\n",
    "                            f\"Statistical Requirements: {stats_analysis}\"\n",
    "                            f\"Architecture and effort estimate: {arch_design}\"\n",
    "                            f\"User Stories and Acceptance Criteria: {user_stories}\"\n",
    "                            f\"UX Researcher Approval: {ux_ok}\"\n",
    "                            f\"Statistician Approval: {stats_ok}\"\n",
    "                            f\"Architect Approval: {arch_ok}\", \n",
    "                            num_reflections=num_reflections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4793ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course. This is the critical next step: translating our comprehensive strategic plan for \"The Deal Room\" into a well-defined, sprint-ready backlog.\n",
      "\n",
      "As the UX Researcher, I have reviewed these user stories and acceptance criteria in detail, and I am absolutely okay with them. This is a significantly more robust and mature backlog. The inclusion of a pre-development \"Spike\" for technical investigation, a dedicated onboarding epic with a clear time-to-value goal, and thoughtful \"unhappy path\" acceptance criteria demonstrates a strong, user-centric approach to agile development.\n",
      "\n",
      "My assessment is that these user stories are an excellent foundation for V1. My feedback will focus on layering our comprehensive research plan directly onto this backlog. This plan is designed to de-risk our core assumptions, ensure we build with confidence, and deliver a product that is not just functional, but genuinely usable, valuable, and trusted.\n",
      "\n",
      "---\n",
      "\n",
      "### **Overall Assessment**\n",
      "\n",
      "**Verdict: Yes, this is an excellent, sprint-ready backlog.**\n",
      "\n",
      "This version is superior because it is more granular, directly addresses key risks we've previously identified (like AE adoption and CRM sync complexity), and builds a thoughtful user journey from the very first interaction. My role is to ensure that as we build this, we are continuously validating our assumptions about user behavior, mental models, and needs.\n",
      "\n",
      "### **A Phased & Continuous Research Approach**\n",
      "\n",
      "Our research plan is designed to be an \"always-on\" function, integrating directly into the development lifecycle to provide continuous insights, rather than acting as a gate at specific points.\n",
      "\n",
      "1.  **Phase 0: Foundational & Generative (Pre-Development, ~2 weeks):** We will immediately conduct generative interviews and journey mapping. The outputs (validated personas, journey maps, template content) will be used to confirm or refine this backlog before the first major development sprint begins.\n",
      "2.  **Phase 1: Iterative Validation (During Development):** As designs for key flows (Onboarding, Deal Room UI) become available in Figma, we will run rapid, weekly prototype usability tests. This provides continuous feedback to the team sprint-by-sprint.\n",
      "3.  **Phase 2: Evaluative & Quantitative (Post-Launch/Beta):** Once we have a beta product, our focus will shift to a longitudinal study. We'll analyze the quantitative data from our analytics (Story 2) and supplement it with surveys and interviews to measure success against our V1 KPIs and inform the V2 roadmap.\n",
      "\n",
      "Woven throughout all phases is a dedicated track for **Accessibility & Inclusive Design.** We will conduct accessibility reviews on designs and test with users who rely on assistive technologies to ensure our product is usable by everyone.\n",
      "\n",
      "---\n",
      "\n",
      "### **Analysis by Epic & Research Validation Plan**\n",
      "\n",
      "#### **Epic: Foundational & Non-Functional Requirements**\n",
      "**Verdict:** Perfect. Starting with a technical spike (Story 0) is a best practice that de-risks the entire project. The analytics instrumentation in Story 2 is well-defined and gives us the tools we need to measure success.\n",
      "**Key User Assumption:** That we can instrument the product in a way that allows us to accurately measure our adoption and engagement KPIs without being intrusive.\n",
      "**Research Validation Plan:**\n",
      "*   My primary role here is to be a key consumer of the data from Story 2. The analytics events (`Deal Room Created`, `Stakeholder Invited`) are the quantitative backbone of our **Longitudinal Beta Study**. I will partner with engineering to ensure the event properties are rich enough to answer key research questions like: \"What is the average time from signup to first Deal Room creation?\", \"Which templates are most popular?\", and \"Is there a correlation between the number of invited stakeholders and the deal closing faster in the CRM?\"\n",
      "\n",
      "#### **Epic: Onboarding & CRM Integration**\n",
      "**Verdict:** Excellent. This is a massive improvement. A dedicated onboarding flow (Story 3) is critical for mitigating the \"Adoption Risk.\" The acceptance criteria for error states (Story 4 & 5) show a mature approach to real-world usability.\n",
      "**Key User Assumption:** That the <2-minute onboarding flow is clear, motivating, and successfully drives users to the \"aha!\" moment of creating their first Deal Room.\n",
      "**Research Validation Plan:**\n",
      "*   This entire epic will be the centerpiece of our **Prototype Usability & Concept Testing**.\n",
      "    *   We will build a clickable Figma prototype of the flow described in Story 3 and 4.\n",
      "    *   We will give participants the task: \"You've just signed up for a new tool to help manage your sales deals. Get the app set up and ready to use.\"\n",
      "    *   We will measure time-on-task to validate the \"<2 minute\" AC and, more importantly, collect qualitative feedback on their confidence and understanding of the value proposition. We will also specifically test the clarity of the error messages for failed connections.\n",
      "\n",
      "#### **Epic: The Deal Room Workspace**\n",
      "**Verdict:** This is the core of the value proposition, and the stories are clear and focused on simplicity, aligning with our \"Non-Goals\" to avoid complex Gantt charts.\n",
      "**Key User Assumption:** That the \"Deal Room\" with a simple task list is the correct mental model and Information Architecture (IA) for how an \"Orchestrator AE\" wants to manage their deals.\n",
      "**Research Validation Plan:**\n",
      "*   This assumption will be validated during our **Phase 0 Generative Interviews**. The primary output will be a **Cross-Functional Deal Journey Map**. This artifact will visually confirm or deny whether a task-based \"room\" metaphor aligns with how AEs actually work, giving us high confidence in this epic before a single line of code is written.\n",
      "\n",
      "#### **Epic: Cross-Functional Collaboration**\n",
      "**Verdict:** This is our key differentiator, and the stories are very strong. Story 9's AC (\"*Crucially*, the stakeholder view **does not** display any sensitive CRM data\") is the most important in the entire backlog from a trust and adoption perspective.\n",
      "**Key User Assumption:** That the \"limited view\" for stakeholders provides enough context for them to be effective without feeling restrictive, and that AEs will *trust* this limited view enough to actually invite them.\n",
      "**Research Validation Plan:**\n",
      "*   This requires a **Dual-Persona Usability Test**. Sourcing the right participants is key.\n",
      "    *   **Recruiting:** We will recruit not only Enterprise AEs but also participants who fit our key non-sales stakeholder profiles. We will prioritize recruiting for the **legal and security roles** for this initial test, as they represent the highest-complexity workflows and risk.\n",
      "    *   **Test Scenario:** Our test will be end-to-end: \"Ask the AE to create a Deal Room and invite their legal counsel to review the MSA. Then, hand the prototype to the 'legal counsel' participant and ask them to find and complete their assigned task.\" Observing this handoff is the only way to truly validate the clarity and effectiveness of the stakeholder view (Story 9) and the notifications (Story 10).\n",
      "\n",
      "#### **Epic: Templates & Process Standardization**\n",
      "**Verdict:** A critical feature for driving efficiency and adoption. The story is well-defined.\n",
      "**Key User Assumption:** That the three pre-defined templates we ship in V1 are genuinely useful and reflect the real-world processes of our target users.\n",
      "**Research Validation Plan:**\n",
      "*   The content for these templates will be a direct output of our **Generative Interviews** and the **Journey Mapping Workshop**. We will not invent these workflows. We will ask AEs and Sales Managers: \"Walk me through the standard steps for a security review. Who is involved? What are the key tasks?\" The answers to those questions become the content of the templates, ensuring they have immediate, out-of-the-box value.\n",
      "\n",
      "---\n",
      "\n",
      "### **Final Verdict**\n",
      "\n",
      "**Yes, this is an excellent, sprint-ready backlog.** It is logically structured, clearly written, and directly supports our product strategy while mitigating key risks. My role as the UX Researcher is now clear: to execute this continuous research plan in parallel with development, feeding insights back to the team to validate assumptions and ensure we are building a product that is not just functional, but usable, valuable, accessible, and trusted by our users.\n"
     ]
    }
   ],
   "source": [
    "print(ux_driven_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5541916",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
