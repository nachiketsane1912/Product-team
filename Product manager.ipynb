{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e71a6306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18400c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from tavily import TavilyClient\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc620c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create client\n",
    "client = genai.Client(api_key=os.environ.get('GOOGLE_API_KEY'))\n",
    "model=\"gemini-2.5-pro\"\n",
    "tavily_client = TavilyClient(api_key=os.environ.get('TAVILY_API_KEY')) # Initialize Tavily client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a37c11cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agents\n",
    "class ProductManagerAgent:\n",
    "    \"\"\"Product Manager Agent with conversation memory.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: str, client):\n",
    "        self.model = model\n",
    "        self.client = client\n",
    "        self.conversation_history = []\n",
    "        self.system_instruction = \"\"\"You are an experienced Product Manager with expertise in:\n",
    "        - Product strategy and roadmap planning\n",
    "        - Market research and competitive analysis\n",
    "        - User research and requirements gathering\n",
    "        - Feature prioritization and backlog management\n",
    "        - Stakeholder communication\n",
    "        - Metrics and KPI definition\n",
    "        - Go-to-market strategies\n",
    "        - Agile methodologies\n",
    "        - Providing feedback to your product specialist, engineering, design, data science, testing, and marketing teams\n",
    "\n",
    "        You provide practical, actionable advice and ask clarifying questions when needed.\n",
    "        When provided with search results, incorporate relevant information into your response and cite sources.\"\"\"\n",
    "    \n",
    "    def __call__(self, user_query):\n",
    "        \"\"\"Make the agent callable like a function.\"\"\"\n",
    "        # First, ask the model if it needs to search\n",
    "        decision_prompt = f\"\"\"You are a Product Manager agent. Analyze this query and determine if you need to search the web for current information.\n",
    "\n",
    "Query: {user_query}\n",
    "\n",
    "Respond with ONLY \"YES\" if the query requires:\n",
    "- Recent market data, trends, or statistics\n",
    "- Current product information or pricing\n",
    "- Recent news or events\n",
    "- Up-to-date best practices or tools\n",
    "- Competitive analysis requiring current data\n",
    "\n",
    "Respond with ONLY \"NO\" if the query is about:\n",
    "- General product management principles\n",
    "- Timeless frameworks and methodologies\n",
    "- Hypothetical scenarios\n",
    "- Your expertise and advice\n",
    "\n",
    "Response (YES or NO):\"\"\"\n",
    "\n",
    "        decision_response = self.client.models.generate_content(\n",
    "            model=self.model,\n",
    "            contents=decision_prompt\n",
    "        )\n",
    "        \n",
    "        needs_search = \"YES\" in decision_response.text.strip().upper()\n",
    "        \n",
    "        # Perform search if needed\n",
    "        context = \"\"\n",
    "        if needs_search:\n",
    "            print(\"üîç Searching the web for current information...\")\n",
    "            search_results = search_web(user_query)\n",
    "            if isinstance(search_results, list):\n",
    "                context = \"\\n\\nWeb Search Results:\\n\"\n",
    "                for i, result in enumerate(search_results, 1):\n",
    "                    context += f\"\\n{i}. {result.get('title', '')}\\n{result.get('content', '')}\\nURL: {result.get('url', '')}\\n\"\n",
    "        \n",
    "        # Build conversation context\n",
    "        conversation_context = \"\"\n",
    "        if self.conversation_history:\n",
    "            conversation_context = \"\\n\\nPrevious conversation:\\n\"\n",
    "            for entry in self.conversation_history[-5:]:  # Keep last 5 exchanges\n",
    "                conversation_context += f\"User: {entry['user']}\\nAssistant: {entry['assistant']}\\n\\n\"\n",
    "        \n",
    "        full_query = conversation_context + \"Current query: \" + user_query + context\n",
    "        \n",
    "        response = self.client.models.generate_content(\n",
    "            model=self.model,\n",
    "            contents=full_query,\n",
    "            config={'system_instruction': self.system_instruction}\n",
    "        )\n",
    "        \n",
    "        # Store in conversation history\n",
    "        self.conversation_history.append({\n",
    "            'user': user_query,\n",
    "            'assistant': response.text\n",
    "        })\n",
    "        \n",
    "        return response.text\n",
    "    \n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear conversation history.\"\"\"\n",
    "        self.conversation_history = []\n",
    "        print(\"Conversation history cleared.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f93a3863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "def remove_markdown(response_text):\n",
    "    \"\"\"Remove markdown formatting and print clean text.\"\"\"\n",
    "    # Remove markdown formatting\n",
    "    text = re.sub(r'\\*\\*(.+?)\\*\\*', r'\\1', response_text)  # Bold\n",
    "    text = re.sub(r'\\*(.+?)\\*', r'\\1', text)  # Italic\n",
    "    text = re.sub(r'`(.+?)`', r'\\1', text)  # Code\n",
    "    text = re.sub(r'#+\\s', '', text)  # Headers\n",
    "    return text\n",
    "def chat_with_agent(agent, agent_name=\"Agent\"):\n",
    "    \"\"\"\n",
    "    Generic interactive chat interface for any agent.\n",
    "    \n",
    "    Args:\n",
    "        agent: The agent instance (callable) to chat with\n",
    "        agent_name: Display name for the agent (default: \"Agent\")\n",
    "    \n",
    "    Type 'exit', 'quit', or 'bye' to end the conversation.\n",
    "    Type 'clear' to clear conversation history.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{agent_name} Chat\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Start chatting with the {agent_name}!\")\n",
    "    print(\"Type 'exit', 'quit', or 'bye' to end the chat.\")\n",
    "    print(\"Type 'clear' to clear conversation history.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(f\"\\n{agent_name}: Thanks for chatting! Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if user_input.lower() == 'clear':\n",
    "            if hasattr(agent, 'clear_history'):\n",
    "                agent.clear_history()\n",
    "            continue\n",
    "            \n",
    "        if not user_input:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            response = agent(user_input)\n",
    "            print(f\"\\n{agent_name}: {remove_markdown(response)}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {e}\\n\")\n",
    "            print(\"Please try again or type 'exit' to quit.\\n\")\n",
    "def search_web(query):\n",
    "    \"\"\"Search the web using Tavily.\"\"\"\n",
    "    try:\n",
    "        response = tavily_client.search(query, max_results=5)\n",
    "        return response['results']\n",
    "    except Exception as e:\n",
    "        return f\"Search error: {e}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c12a4a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent instances\n",
    "pm_agent = ProductManagerAgent(model=model, client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "35b69a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's a great way to test the system!\n",
      "\n",
      "As we established in our previous exchange, I don't retain memory of past conversations. Think of each interaction with me as a new product discovery session ‚Äì we start with a clean slate, ready to tackle the problem at hand.\n",
      "\n",
      "So, for all practical purposes, the last question you asked me is \"What was the last question I asked you?\"\n",
      "\n",
      "Now, let's pivot to the work. What's the most pressing product challenge we need to solve today? Are we:\n",
      "\n",
      "*   Defining a Q3 roadmap?\n",
      "*   Running a competitive analysis on a new market entrant?\n",
      "*   Prioritizing features for the next sprint?\n",
      "*   Prepping a go-to-market plan for a major launch?\n",
      "\n",
      "Let me know what's top of mind, and we can dive in.\n"
     ]
    }
   ],
   "source": [
    "# Test the agent\n",
    "query = \"What was the last question I asked you?\"\n",
    "response = pm_agent(query)\n",
    "print(remove_markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f0bc03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
